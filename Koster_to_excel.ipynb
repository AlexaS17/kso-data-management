{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Koster_to_excel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nST_NIefwj5C"
      },
      "source": [
        "# Koster data to excel\n",
        "\n",
        "The following scripts are set up to retrieve the annotations, comments and tags from the Koster seafloor observatory and translate them to excel-friendly format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItN_oYTkwj5D"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMtnwGLswj5D"
      },
      "source": [
        "### Install required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjHJ-llOx0eZ"
      },
      "source": [
        "We use the \"panoptes_client\" package to communicate with Zooniverse. If you don't have it installed, run the command below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5sxXdZex2M7"
      },
      "source": [
        "!pip install panoptes_client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygHmKZGlx8vb"
      },
      "source": [
        "### Load required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRLefFV2yAfO"
      },
      "source": [
        "import io\n",
        "import zipfile\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "from datetime import date\n",
        "from panoptes_client import (\n",
        "    SubjectSet,\n",
        "    Subject,\n",
        "    Project,\n",
        "    Panoptes,\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMKYQ2v_yEp4"
      },
      "source": [
        "### Connect to Zooniverse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh356o6nyO6r"
      },
      "source": [
        "zoo_user = \"user\"\n",
        "zoo_pass = \"pass\"\n",
        "\n",
        "# Connect to Zooniverse with your username and password\n",
        "auth = Panoptes.connect(username=zoo_user, password=zoo_pass)\n",
        "\n",
        "if not auth.logged_in:\n",
        "    raise AuthenticationError(\"Your credentials are invalid. Please try again.\")\n",
        "\n",
        "# Connect to the Zooniverse project (our project # is 9747)\n",
        "project = Project(9747)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDoVfs0XzfVr"
      },
      "source": [
        "# Download Zooniverse subjects information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doHKpJHiwj5E"
      },
      "source": [
        "# Get info of subjects uploaded to the project\n",
        "export = project.get_export(\"subjects\")\n",
        "\n",
        "# Save the subjects info as pandas data frame\n",
        "subjects_df = pd.read_csv(\n",
        "    io.StringIO(export.content.decode(\"utf-8\")),\n",
        "    usecols=[\n",
        "        \"subject_id\",\n",
        "        \"metadata\",\n",
        "        \"created_at\",\n",
        "        \"workflow_id\",\n",
        "        \"subject_set_id\",\n",
        "        \"classifications_count\",\n",
        "        \"retired_at\",\n",
        "        \"retirement_reason\",\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HqluuLa0t8G"
      },
      "source": [
        "## Format subject information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "injQq7YE1lNe"
      },
      "source": [
        "### Define project-specific functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZUATgrY2gKA"
      },
      "source": [
        "Function to extract the metadata from subjects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqW5Pd5A1t0g"
      },
      "source": [
        "def extract_metadata(subj_df):\n",
        "\n",
        "    # Reset index of df\n",
        "    subj_df = subj_df.reset_index(drop=True).reset_index()\n",
        "\n",
        "    # Flatten the metadata information\n",
        "    meta_df = pd.json_normalize(subj_df.metadata.apply(json.loads))\n",
        "\n",
        "    # Drop metadata and index columns from original df\n",
        "    subj_df = subj_df.drop(columns=[\"metadata\", \"index\",])\n",
        "\n",
        "    return subj_df, meta_df"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sme3HTFu1MHe"
      },
      "source": [
        "### Format subjects uploaded automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0a9163_2E6f"
      },
      "source": [
        "# Specify the date when we first started uploading subjects automatically\n",
        "first_auto_upload = \"2020-05-29 00:00:00 UTC\"\n",
        "\n",
        "# Select automatically uploaded frames\n",
        "auto_subjects_df = subjects_df[subjects_df[\"created_at\"] > first_auto_upload]\n",
        "\n",
        "# Extract metadata from automatically uploaded frames\n",
        "auto_subjects_df, auto_subjects_meta = extract_metadata(auto_subjects_df)\n",
        "\n",
        "# Combine metadata info with the subjects df\n",
        "auto_subjects_df = pd.concat([auto_subjects_df, auto_subjects_meta], axis=1)\n",
        "\n",
        "# Select only relevant columns\n",
        "auto_subjects_df = auto_subjects_df[\n",
        "    [\"subject_id\", \"retired_at\", \"subject_type\"]\n",
        "]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLsq1BVJ2CMW"
      },
      "source": [
        "### Format subjects uploaded manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUX56zIE00E2"
      },
      "source": [
        "# Specify the starting date when clips were manually uploaded\n",
        "first_manual_upload = \"2019-11-17 00:00:00 UTC\"\n",
        "\n",
        "# Select subjects uploaded manually\n",
        "man_clips_df = (\n",
        "    subjects_df[\n",
        "        (subjects_df[\"metadata\"].str.contains(\".mp4\"))\n",
        "        & (\n",
        "            subjects_df[\"created_at\"].between(\n",
        "                first_manual_upload, first_auto_upload\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        "    .reset_index(drop=True)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Specify the type of subject\n",
        "man_clips_df[\"subject_type\"] = \"clip\"\n",
        "\n",
        "# Extract metadata from manually uploaded clips\n",
        "man_clips_df, man_clips_meta = extract_metadata(man_clips_df)\n",
        "\n",
        "# Combine metadata info with the subjects df\n",
        "man_clips_df = pd.concat([man_clips_df, man_clips_meta], axis=1)\n",
        "\n",
        "# Select only relevant columns\n",
        "man_clips_df = man_clips_df[\n",
        "    [\"subject_id\", \"retired_at\", \"subject_type\"]\n",
        "]\n",
        "\n",
        "# Combine all uploaded subjects\n",
        "subjects = pd.merge(man_clips_df, auto_subjects_df, how=\"outer\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkRr7l4FPIVs"
      },
      "source": [
        "# Download Zooniverse classifications information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JknNX3ZpPVFq"
      },
      "source": [
        "# Get classifications from Zooniverse\n",
        "export = project.get_export(\"classifications\")\n",
        "\n",
        "# Save the response as pandas data frame\n",
        "class_df = pd.read_csv(\n",
        "    io.StringIO(export.content.decode(\"utf-8\")),\n",
        "    usecols=[\n",
        "        \"subject_ids\",\n",
        "        \"classification_id\",\n",
        "        \"workflow_id\",\n",
        "        \"workflow_version\",\n",
        "        \"annotations\",\n",
        "        \"created_at\",\n",
        "        \"user_name\",\n",
        "    ],\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RuKdtJCQQkA"
      },
      "source": [
        "## Specify the video and frame workflows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgosFjI7QYJQ"
      },
      "source": [
        "workflow_clip = 11767\n",
        "workflow_clip_version = 227\n",
        "workflow_frame = 12852\n",
        "workflow_frame_version = 21.85 #Should this be 21.43?"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFBeHSwTPybJ"
      },
      "source": [
        "### Format video annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzgxh0HgPzRU"
      },
      "source": [
        "# Filter clip classifications\n",
        "class_clip = class_df[\n",
        "    (class_df.workflow_id >= workflow_clip)\n",
        "    & (class_df.workflow_version >= workflow_clip_version)\n",
        "].reset_index()\n",
        "\n",
        "# Create an empty list\n",
        "rows_list = []\n",
        "\n",
        "# Loop through each classification submitted by the users\n",
        "for index, row in class_clip.iterrows():\n",
        "    # Load annotations as json format\n",
        "    annotations = json.loads(row[\"annotations\"])\n",
        "\n",
        "    # Select the information from the species identification task\n",
        "    for ann_i in annotations:\n",
        "        if ann_i[\"task\"] == \"T4\":\n",
        "\n",
        "            # Select each species annotated and flatten the relevant answers\n",
        "            for value_i in ann_i[\"value\"]:\n",
        "                choice_i = {}\n",
        "                # If choice = 'nothing here', set follow-up answers to blank\n",
        "                if value_i[\"choice\"] == \"NOTHINGHERE\":\n",
        "                    f_time = \"\"\n",
        "                    inds = \"\"\n",
        "                # If choice = species, flatten follow-up answers\n",
        "                else:\n",
        "                    answers = value_i[\"answers\"]\n",
        "                    for k in answers.keys():\n",
        "                        if \"FIRSTTIME\" in k:\n",
        "                            f_time = answers[k].replace(\"S\", \"\")\n",
        "                        if \"INDIVIDUAL\" in k:\n",
        "                            inds = answers[k]\n",
        "\n",
        "                # Save the species of choice, class and subject id\n",
        "                choice_i.update(\n",
        "                    {\n",
        "                        \"classification_id\": row[\"classification_id\"],\n",
        "                        \"label\": value_i[\"choice\"],\n",
        "                        \"first_seen\": f_time,\n",
        "                        \"how_many\": inds,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                rows_list.append(choice_i)\n",
        "\n",
        "# Create a data frame with annotations as rows\n",
        "class_clips_df = pd.DataFrame(\n",
        "    rows_list, columns=[\"classification_id\", \"label\", \"first_seen\", \"how_many\"]\n",
        ")\n",
        "\n",
        "# Specify the type of columns of the df\n",
        "class_clips_df[\"how_many\"] = pd.to_numeric(class_clips_df[\"how_many\"])\n",
        "class_clips_df[\"first_seen\"] = pd.to_numeric(class_clips_df[\"first_seen\"])\n",
        "\n",
        "# Add subject id to each annotation\n",
        "class_clips_df = pd.merge(\n",
        "    class_clips_df,\n",
        "    class_clip.drop(columns=[\"annotations\"]),\n",
        "    how=\"left\",\n",
        "    on=\"classification_id\",\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LdI_z19Q8Vx"
      },
      "source": [
        "## Format frame annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPfPZCVokkTF"
      },
      "source": [
        "# Filter frame classifications\n",
        "class_frame = class_df[\n",
        "    (class_df.workflow_id >= workflow_frame)\n",
        "    & (class_df.workflow_version >= workflow_frame_version)\n",
        "].reset_index()    \n",
        "\n",
        "# Create an empty list\n",
        "rows_list = []\n",
        "\n",
        "# Loop through each classification submitted by the users\n",
        "for index, row in class_frame.iterrows():\n",
        "    # Load annotations as json format\n",
        "    annotations = json.loads(row[\"annotations\"])\n",
        "\n",
        "    # Select the information from each annotation\n",
        "    for ann_i in annotations:\n",
        "      choice_i = {}\n",
        "\n",
        "      if not ann_i[\"value\"]:\n",
        "        # Save the annotation and class id\n",
        "        choice_i.update(\n",
        "            {\n",
        "                \"classification_id\": row[\"classification_id\"],\n",
        "                \"label\": \"no_coral\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "      else:\n",
        "        # Save the annotation and class id\n",
        "        choice_i.update(\n",
        "            {\n",
        "                \"classification_id\": row[\"classification_id\"],\n",
        "                \"label\": \"coral\",\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        \n",
        "      rows_list.append(choice_i)\n",
        "\n",
        "# Create a data frame with annotations as rows\n",
        "class_frame_df = pd.DataFrame(\n",
        "    rows_list, columns=[\"classification_id\", \"label\"]\n",
        ")\n",
        "\n",
        "# Add subject id to each annotation\n",
        "class_frame_df = pd.merge(\n",
        "    class_frame_df,\n",
        "    class_frame.drop(columns=[\"annotations\"]),\n",
        "    how=\"left\",\n",
        "    on=\"classification_id\",\n",
        ")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKZGrSv7SR0m"
      },
      "source": [
        "## Combine classifications and subject information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLsTdbJOSlTt"
      },
      "source": [
        "# Combine video and frame classifications\n",
        "annot_df = pd.merge(class_clips_df, class_frame_df, how=\"outer\")\n",
        "\n",
        "# Drop workflow and n_users columns\n",
        "annot_df = annot_df.drop(columns=[\"workflow_id\", \"workflow_version\"])\n",
        "\n",
        "# Rename the subject_id field\n",
        "annot_df = annot_df.rename(\n",
        "    columns={\"subject_ids\": \"subject_id\"}\n",
        ")\n",
        "\n",
        "# Add the subject information\n",
        "annot_df = pd.merge(\n",
        "    annot_df,\n",
        "    subjects,\n",
        "    how=\"left\",\n",
        "    on=\"subject_id\",\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu4ZriVp7Iuv"
      },
      "source": [
        "## Save classifications as csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_KGEDjmTJCp"
      },
      "source": [
        "annot_df.to_csv('annotations_data.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha4BT45e7mb9"
      },
      "source": [
        "# Download Zooniverse comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh8tMckM7pjV"
      },
      "source": [
        "# Get comments from Zooniverse\n",
        "export = project.get_export('talk_comments')\n",
        "export = gzip.decompress(export.content)\n",
        "\n",
        "# Save the response as pandas data frame\n",
        "data = json.loads(export.decode('utf-8')[export.decode('utf-8').find('['):export.decode('utf-8').rfind(']')+1])\n",
        "comment_df = pd.DataFrame(data)[[\n",
        "        \"board_title\",\n",
        "        \"comment_body\",\n",
        "        \"comment_focus_id\",\n",
        "        \"comment_id\",\n",
        "        \"discussion_title\",\n",
        "        \"comment_created_at\",\n",
        "        \"comment_user_login\",\n",
        "    ]]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CnhjqC_CN3z"
      },
      "source": [
        "## Combine comments and subject Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZJAOmBUCSf6"
      },
      "source": [
        "# Rename the subject_id field\n",
        "comment_df = comment_df.rename(\n",
        "    columns={\"comment_focus_id\": \"subject_id\"}\n",
        ")\n",
        "\n",
        "# Add the subject information\n",
        "comment_df = pd.merge(\n",
        "    comment_df,\n",
        "    subjects,\n",
        "    how=\"left\",\n",
        "    on=\"subject_id\",\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nB6XA3zpUV7"
      },
      "source": [
        "# Remove comments from the Zooniverse team (i.e. non-user comments)\n",
        "comment_df = comment_df.dropna(subset=['subject_id'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaGMNQ2A7ps0"
      },
      "source": [
        "# Download Zooniverse tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUP7Ppgip9lJ"
      },
      "source": [
        "# Get comments from Zooniverse\n",
        "export = project.get_export('talk_tags')\n",
        "export = gzip.decompress(export.content)\n",
        "\n",
        "# Save the response as pandas data frame\n",
        "data = json.loads(export.decode('utf-8')[export.decode('utf-8').find('['):export.decode('utf-8').rfind(']')+1])\n",
        "tag_df = pd.DataFrame(data)[[\"name\", \"comment_id\"]]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIe_DwsMumgk"
      },
      "source": [
        "## Combine tags and comments information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG7q4VA2umgk"
      },
      "source": [
        "# Add the comments information\n",
        "comment_df = pd.merge(\n",
        "    comment_df,\n",
        "    tag_df,\n",
        "    how=\"left\",\n",
        "    on=\"comment_id\",\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OnWhwyryM_6"
      },
      "source": [
        "## Save comments as csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIbhUwhcumgk"
      },
      "source": [
        "comment_df.to_csv('comments_data.csv')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9REo1aGL7yh"
      },
      "source": [
        "Find out the period when the clip and frame workflows were active \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEZikLBqLQMr"
      },
      "source": [
        "# Filter only for subjects that are frames\n",
        "annot_frames = annot_df[(annot_df.subject_type == \"frame\")]\n",
        "\n",
        "# Select the first frame annotation\n",
        "first_day = annot_frames['created_at'].min()\n",
        "\n",
        "# Date when the last frame was retired\n",
        "last_day = annot_frames['retired_at'].max()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RyQiwu9OMO5u",
        "outputId": "0df233aa-6fd7-4705-edd1-7b432e5657f8"
      },
      "source": [
        "first_day"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-05-29 07:39:06 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ureXXHFVN_Nd",
        "outputId": "abbb4b4b-c60f-4252-8af8-84b0f2060ee4"
      },
      "source": [
        "last_day"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2020-06-01 15:08:30 UTC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Kcc1Osut6O"
      },
      "source": [
        "# END"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}