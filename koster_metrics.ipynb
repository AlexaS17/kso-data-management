{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koster Lab Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import db_utils, zooniverse_utils\n",
    "import pandas as pd\n",
    "import io, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for the db\n",
    "db_path = \"/data/database/demo.db\"\n",
    "\n",
    "# Specify Google Drive ids of the csv files with information about the species choices,\n",
    "# original movies and duplicated clips\n",
    "sp_file_id = \"1dnueH3BjJrMK8buVjfyFbxfu0E-5dX7Z\"\n",
    "mv_file_id = \"1LL-Ah_FIkBiGKEldYvuhNeL2NyOvKBip\"\n",
    "dp_file_id = \"1z72CqTtEBtqk6936H1YNrCjc5NRopF0g\"\n",
    "\n",
    "# Specify username and password of a valid zooniverse account\n",
    "user_zoo = \"user\"\n",
    "pass_zoo = \"pass\"\n",
    "\n",
    "# Species choice\n",
    "species = 'DEEPWATERCORAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Zooniverse workflows of interest and their versions\n",
    "workflow_clip = 11767\n",
    "workflow_clip_version = 227\n",
    "workflow_frame = 12852\n",
    "workflow_frame_version = 21.85\n",
    "\n",
    "# Specify the agreement threshold required among cit scientists\n",
    "agg_user_clip = 0.8\n",
    "agg_user_frames = 0.8\n",
    "\n",
    "# Specifiy the min number of different Zooniverse users required per subject\n",
    "min_users_clip = 3\n",
    "min_users_frames = 5\n",
    "\n",
    "# Frame user agreement threshold\n",
    "iua = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Koster DB and retrieve relevant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db_utils.create_connection(\"/data/database/demo.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = pd.read_sql_query(\"SELECT * FROM subjects\", conn)\n",
    "movies = pd.read_sql_query(\"SELECT * FROM movies\", conn)\n",
    "sites = pd.read_sql_query(\"SELECT * FROM sites\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Clips Aggregate Table based on thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Zooniverse project\n",
    "project = zooniverse_utils.auth_session(user_zoo, pass_zoo)\n",
    "\n",
    "# Get the classifications from the project\n",
    "export = project.get_export(\"classifications\")\n",
    "\n",
    "# Save the response as pandas data frame\n",
    "class_df = pd.read_csv(\n",
    "    io.StringIO(export.content.decode(\"utf-8\")),\n",
    "    usecols=[\n",
    "        \"subject_ids\",\n",
    "        \"classification_id\",\n",
    "        \"workflow_id\",\n",
    "        \"workflow_version\",\n",
    "        \"annotations\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Filter clip classifications\n",
    "class_df = class_df[\n",
    "    (class_df.workflow_id >= workflow_clip)\n",
    "    & (class_df.workflow_version >= workflow_clip_version)\n",
    "].reset_index()\n",
    "\n",
    "# Drop worflow columns\n",
    "class_df = class_df.drop(columns=[\"workflow_id\", \"workflow_version\"])\n",
    "\n",
    "# Create an empty list\n",
    "rows_list = []\n",
    "\n",
    "# Loop through each classification submitted by the users\n",
    "for index, row in class_df.iterrows():\n",
    "    # Load annotations as json format\n",
    "    annotations = json.loads(row[\"annotations\"])\n",
    "\n",
    "    # Select the information from the species identification task\n",
    "    for ann_i in annotations:\n",
    "        if ann_i[\"task\"] == \"T4\":\n",
    "\n",
    "            # Select each species annotated and flatten the relevant answers\n",
    "            for value_i in ann_i[\"value\"]:\n",
    "                choice_i = {}\n",
    "                # If choice = 'nothing here', set follow-up answers to blank\n",
    "                if value_i[\"choice\"] == \"NOTHINGHERE\":\n",
    "                    f_time = \"\"\n",
    "                    inds = \"\"\n",
    "                # If choice = species, flatten follow-up answers\n",
    "                else:\n",
    "                    answers = value_i[\"answers\"]\n",
    "                    for k in answers.keys():\n",
    "                        if \"FIRSTTIME\" in k:\n",
    "                            f_time = answers[k].replace(\"S\", \"\")\n",
    "                        if \"INDIVIDUAL\" in k:\n",
    "                            inds = answers[k]\n",
    "\n",
    "                # Save the species of choice, class and subject id\n",
    "                choice_i.update(\n",
    "                    {\n",
    "                        \"classification_id\": row[\"classification_id\"],\n",
    "                        \"label\": value_i[\"choice\"],\n",
    "                        \"first_seen\": f_time,\n",
    "                        \"how_many\": inds,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                rows_list.append(choice_i)\n",
    "\n",
    "# Create a data frame with annotations as rows\n",
    "annot_df = pd.DataFrame(\n",
    "    rows_list, columns=[\"classification_id\", \"label\", \"first_seen\", \"how_many\"]\n",
    ")\n",
    "\n",
    "# Specify the type of columns of the df\n",
    "annot_df[\"how_many\"] = pd.to_numeric(annot_df[\"how_many\"])\n",
    "annot_df[\"first_seen\"] = pd.to_numeric(annot_df[\"first_seen\"])\n",
    "\n",
    "# Add subject id to each annotation\n",
    "annot_df = pd.merge(\n",
    "    annot_df,\n",
    "    class_df.drop(columns=[\"annotations\"]),\n",
    "    how=\"left\",\n",
    "    on=\"classification_id\",\n",
    ")\n",
    "\n",
    "# Clear duplicated subjects\n",
    "if dp_file_id:\n",
    "    annot_df = db_utils.combine_duplicates(annot_df, dp_file_id)\n",
    "\n",
    "# Calculate the number of users that classified each subject\n",
    "annot_df[\"n_users\"] = annot_df.groupby(\"subject_ids\")[\n",
    "    \"classification_id\"\n",
    "].transform(\"nunique\")\n",
    "\n",
    "# Select subjects with at least n different user classifications\n",
    "annot_df = annot_df[annot_df.n_users >= min_users_clip]\n",
    "\n",
    "# Calculate the proportion of users that agreed on their annotations\n",
    "annot_df[\"class_n\"] = annot_df.groupby([\"subject_ids\", \"label\"])[\n",
    "    \"classification_id\"\n",
    "].transform(\"count\")\n",
    "\n",
    "annot_df[\"class_prop\"] = annot_df.class_n / annot_df.n_users\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip classification statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users classifying clips ranged from 4 to 32\n",
      "Median number of users classifying clips 9.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users classifying clips ranged from {annot_df.n_users.min()} to {annot_df.n_users.max()}\")\n",
    "print(f\"Median number of users classifying clips {annot_df.n_users.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of agreement in classifying clips ranged from 0.03125 to 1.0\n",
      "Median agreement prop of users classifying clips 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of agreement in classifying clips ranged from {annot_df.class_prop.min()} to {annot_df.class_prop.max()}\")\n",
    "print(f\"Median agreement prop of users classifying clips {annot_df.class_prop.median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add movie and site information to subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df = pd.merge(annot_df, subjects, left_on='subject_ids', right_on='id')\n",
    "annot_df = pd.merge(annot_df, movies, left_on=\"movie_id\", right_on=\"id\")\n",
    "annot_df = pd.merge(annot_df, sites, left_on=\"site_id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(df, agg_thresh):\n",
    "    return annot_df[(annot_df.label == species) & (annot_df.class_prop >= agg_thresh)].sort_values(\n",
    "        by=[\"class_prop\"], ascending=False)[[\"filename_x\", \"fpath\", \"name\",\n",
    "                                             \"first_seen\", \"how_many\", \"label\", \"class_prop\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clips for species DEEPWATERCORAL: 1945\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of clips for species {species}: {len(get_annotations(annot_df, 0.0).filename_x.value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clips for species with agreement 0.8 for DEEPWATERCORAL:       194\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of clips for species with agreement {agg_user_clip} for {species}: \\\n",
    "      {len(get_annotations(annot_df, 0.8).filename_x.value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clips for species with agreement 0.5 for DEEPWATERCORAL:       733\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of clips for species with agreement {0.5} for {species}: \\\n",
    "      {len(get_annotations(annot_df, 0.5).filename_x.value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, csv, json\n",
    "import requests, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "from panoptes_client import Project, Panoptes\n",
    "from collections import OrderedDict, Counter\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_iou(boxA, boxB):\n",
    "\n",
    "    # Compute edges\n",
    "    temp_boxA = boxA.copy()\n",
    "    temp_boxB = boxB.copy()\n",
    "    temp_boxA[2], temp_boxA[3] = (\n",
    "        temp_boxA[0] + temp_boxA[2],\n",
    "        temp_boxA[1] + temp_boxA[3],\n",
    "    )\n",
    "    temp_boxB[2], temp_boxB[3] = (\n",
    "        temp_boxB[0] + temp_boxB[2],\n",
    "        temp_boxB[1] + temp_boxB[3],\n",
    "    )\n",
    "\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(temp_boxA[0], temp_boxB[0])\n",
    "    yA = max(temp_boxA[1], temp_boxB[1])\n",
    "    xB = min(temp_boxA[2], temp_boxB[2])\n",
    "    yB = min(temp_boxA[3], temp_boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "    if interArea == 0:\n",
    "        return 1\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = abs((temp_boxA[2] - temp_boxA[0]) * (temp_boxA[3] - temp_boxA[1]))\n",
    "    boxBArea = abs((temp_boxB[2] - temp_boxB[0]) * (temp_boxB[3] - temp_boxB[1]))\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return 1 - iou\n",
    "\n",
    "\n",
    "def filter_bboxes(total_users, users, bboxes, obj, eps, iua):\n",
    "\n",
    "    # If at least half of those who saw this frame decided that there was an object\n",
    "    user_count = pd.Series(users).nunique()\n",
    "    if user_count / total_users >= obj:\n",
    "        # Get clusters of annotation boxes based on iou criterion\n",
    "        cluster_ids = DBSCAN(min_samples=1, metric=bb_iou, eps=eps).fit_predict(bboxes)\n",
    "        # Count the number of users within each cluster\n",
    "        counter_dict = Counter(cluster_ids)\n",
    "        # Accept a cluster assignment if at least 80% of users agree on annotation\n",
    "        passing_ids = [k for k, v in counter_dict.items() if v / user_count >= iua]\n",
    "\n",
    "        indices = np.isin(cluster_ids, passing_ids)\n",
    "\n",
    "        final_boxes = []\n",
    "        for i in passing_ids:\n",
    "            # Compute median over all accepted bounding boxes\n",
    "            boxes = np.median(np.array(bboxes)[np.where(cluster_ids == i)], axis=0)\n",
    "            final_boxes.append(boxes)\n",
    "\n",
    "        return indices, final_boxes\n",
    "\n",
    "    else:\n",
    "        return [], bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = zooniverse_utils.auth_session(user_zoo, pass_zoo)\n",
    "\n",
    "# Get the export classifications\n",
    "export = project.get_export(\"classifications\")\n",
    "\n",
    "# Save the response as pandas data frame\n",
    "rawdata = pd.read_csv(\n",
    "    io.StringIO(export.content.decode(\"utf-8\")),\n",
    "    usecols=[\n",
    "        \"user_name\",\n",
    "        \"subject_ids\",\n",
    "        \"subject_data\",\n",
    "        \"classification_id\",\n",
    "        \"workflow_id\",\n",
    "        \"workflow_version\",\n",
    "        \"annotations\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Filter w2 classifications\n",
    "w2_data = rawdata[\n",
    "    (rawdata.workflow_id >= workflow_frame)\n",
    "    & (rawdata.workflow_version >= workflow_frame_version)\n",
    "].reset_index()\n",
    "\n",
    "# Clear duplicated subjects\n",
    "if dp_file_id:\n",
    "    w2_data = db_utils.combine_duplicates(w2_data, dp_file_id)\n",
    "\n",
    "# Calculate the number of users that classified each subject\n",
    "w2_data[\"n_users\"] = w2_data.groupby(\"subject_ids\")[\n",
    "    \"classification_id\"\n",
    "].transform(\"nunique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames for species DEEPWATERCORAL: 533\n",
      "Number of users classifying clips ranged from 5 to 12\n",
      "Median number of users classifying clips 5.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of frames for species {species}: {len(w2_data.groupby('subject_ids'))}\")\n",
    "\n",
    "print(f\"Number of users classifying clips ranged from {w2_data.n_users.min()} to {w2_data.n_users.max()}\")\n",
    "print(f\"Median number of users classifying clips {w2_data.n_users.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select frames with at least n different user classifications\n",
    "w2_data = w2_data[w2_data.n_users >= min_users_frames]\n",
    "\n",
    "# Drop workflow and n_users columns\n",
    "w2_data = w2_data.drop(columns=[\"workflow_id\", \"workflow_version\", \"n_users\"])\n",
    "\n",
    "# Extract the video filename and annotation details\n",
    "w2_data[[\"filename\", \"frame_number\", \"label\"]] = pd.DataFrame(\n",
    "    w2_data[\"subject_data\"]\n",
    "    .apply(\n",
    "        lambda x: [\n",
    "            {\n",
    "                \"filename\": v[\"movie_filepath\"],\n",
    "                \"frame_number\": v[\"frame_number\"],\n",
    "                \"label\": v[\"label\"],\n",
    "            }\n",
    "            for k, v in json.loads(x).items()\n",
    "        ][0]\n",
    "    )\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Convert to dictionary entries\n",
    "w2_data[\"filename\"] = w2_data[\"filename\"].apply(lambda x: {\"filename\": x})\n",
    "w2_data[\"frame_number\"] = w2_data[\"frame_number\"].apply(\n",
    "    lambda x: {\"frame_number\": x}\n",
    ")\n",
    "w2_data[\"label\"] = w2_data[\"label\"].apply(lambda x: {\"label\": x})\n",
    "w2_data[\"user_name\"] = w2_data[\"user_name\"].apply(lambda x: {\"user_name\": x})\n",
    "w2_data[\"subject_id\"] = w2_data[\"subject_ids\"].apply(lambda x: {\"subject_id\": x})\n",
    "w2_data[\"annotation\"] = w2_data[\"annotations\"].apply(\n",
    "    lambda x: literal_eval(x)[0][\"value\"], 1\n",
    ")\n",
    "\n",
    "# Extract annotation metadata\n",
    "w2_data[\"annotation\"] = w2_data[\n",
    "    [\"filename\", \"frame_number\", \"label\", \"annotation\", \"user_name\", \"subject_id\"]\n",
    "].apply(\n",
    "    lambda x: [\n",
    "        OrderedDict(\n",
    "            list(x[\"filename\"].items())\n",
    "            + list(x[\"frame_number\"].items())\n",
    "            + list(x[\"label\"].items())\n",
    "            + list(x[\"annotation\"][i].items())\n",
    "            + list(x[\"user_name\"].items())\n",
    "            + list(x[\"subject_id\"].items())\n",
    "        )\n",
    "        for i in range(len(x[\"annotation\"]))\n",
    "    ]\n",
    "    if len(x[\"annotation\"]) > 0\n",
    "    else [\n",
    "        OrderedDict(\n",
    "            list(x[\"filename\"].items())\n",
    "            + list(x[\"frame_number\"].items())\n",
    "            + list(x[\"label\"].items())\n",
    "            + list(x[\"user_name\"].items())\n",
    "            + list(x[\"subject_id\"].items())\n",
    "        )\n",
    "    ],\n",
    "    1,\n",
    ")\n",
    "\n",
    "# Convert annotation to format which the tracker expects\n",
    "ds = [\n",
    "    OrderedDict(\n",
    "        {\n",
    "            \"user\": i[\"user_name\"],\n",
    "            \"filename\": i[\"filename\"],\n",
    "            \"class_name\": i[\"label\"],\n",
    "            \"start_frame\": i[\"frame_number\"],\n",
    "            \"x\": int(i[\"x\"]) if \"x\" in i else None,\n",
    "            \"y\": int(i[\"y\"]) if \"y\" in i else None,\n",
    "            \"w\": int(i[\"width\"]) if \"width\" in i else None,\n",
    "            \"h\": int(i[\"height\"]) if \"height\" in i else None,\n",
    "            \"subject_id\": i[\"subject_id\"] if \"subject_id\" in i else None,\n",
    "        }\n",
    "    )\n",
    "    for i in w2_data.annotation.explode()\n",
    "    if i is not None and i is not np.nan\n",
    "]\n",
    "\n",
    "# Get prepared annotations\n",
    "w2_full = pd.DataFrame(ds)\n",
    "w2_annotations = w2_full[w2_full[\"x\"].notnull()]\n",
    "new_rows = []\n",
    "final_indices = []\n",
    "for name, group in w2_annotations.groupby(\n",
    "    [\"filename\", \"class_name\", \"start_frame\"]\n",
    "):\n",
    "\n",
    "    filename, class_name, start_frame = name\n",
    "\n",
    "    total_users = w2_full[\n",
    "        (w2_full.filename == filename)\n",
    "        & (w2_full.class_name == class_name)\n",
    "        & (w2_full.start_frame == start_frame)\n",
    "    ][\"user\"].nunique()\n",
    "\n",
    "    # Filter bboxes using IOU metric (essentially a consensus metric)\n",
    "    # Keep only bboxes where mean overlap exceeds this threshold\n",
    "    indices, new_group = filter_bboxes(\n",
    "        total_users=total_users,\n",
    "        users=[i[0] for i in group.values],\n",
    "        bboxes=[np.array((i[4], i[5], i[6], i[7])) for i in group.values],\n",
    "        obj=0.8,\n",
    "        eps=0.5,\n",
    "        iua=iua,\n",
    "    )\n",
    "\n",
    "    subject_ids = [i[8] for i in group.values[indices]]\n",
    "\n",
    "    for ix, box in zip(subject_ids, new_group):\n",
    "        new_rows.append((filename, class_name, start_frame, ix,) + tuple(box))\n",
    "\n",
    "w2_annotations = pd.DataFrame(\n",
    "    new_rows,\n",
    "    columns=[\n",
    "        \"filename\",\n",
    "        \"class_name\",\n",
    "        \"start_frame\",\n",
    "        \"subject_id\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"w\",\n",
    "        \"h\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Get species id for each species\n",
    "conn = db_utils.create_connection(db_path)\n",
    "\n",
    "# Get subject table\n",
    "subjects_df = pd.read_sql_query(\n",
    "    \"SELECT id, frame_exp_sp_id, movie_id FROM subjects\", conn\n",
    ")\n",
    "subjects_df = subjects_df.rename(\n",
    "    columns={\"id\": \"subject_id\", \"frame_exp_sp_id\": \"species_id\"}\n",
    ")\n",
    "\n",
    "w2_annotations = pd.merge(\n",
    "    w2_annotations,\n",
    "    subjects_df,\n",
    "    how=\"left\",\n",
    "    left_on=\"subject_id\",\n",
    "    right_on=\"subject_id\",\n",
    "    validate=\"many_to_one\",\n",
    ")\n",
    "\n",
    "# Filter out invalid movies\n",
    "w2_annotations = w2_annotations[w2_annotations.movie_id.notnull()][\n",
    "    [\"species_id\", \"class_name\", \"x\", \"y\", \"w\", \"h\", \"subject_id\", \"movie_id\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by species\n",
    "w2_annotations['class_name'] = w2_annotations.class_name.apply(lambda x: x.upper().replace(\" \", \"\"), 1)\n",
    "w2_annotations = w2_annotations[w2_annotations.class_name == species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with movies and site to see distribution of instances\n",
    "w2_annotations = pd.merge(w2_annotations, movies, left_on='movie_id', right_on='id')\n",
    "w2_annotations = pd.merge(w2_annotations, sites, left_on='site_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies for species DEEPWATERCORAL: 17\n",
      "Number of subjects for species DEEPWATERCORAL: 409\n",
      "Number of instances for species DEEPWATERCORAL: 557\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of movies for species {species}: {len(w2_annotations.fpath.value_counts())}\")\n",
    "print(f\"Number of subjects for species {species}: {len(w2_annotations.groupby('subject_id'))}\")\n",
    "print(f\"Number of instances for species {species}: {len(w2_annotations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site distribution DEEPWATERCORAL: \n",
      "\n",
      "missing                                  325\n",
      "Revet, sacken                            149\n",
      "sackenrevet alfa                          45\n",
      "Revet, Sacken                             37\n",
      "o. sundet Storo - Torso,utsidan ranna      1\n",
      "Name: name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Site distribution {species}: \\n\\n{w2_annotations['name'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie distribution DEEPWATERCORAL: \n",
      "\n",
      "/uploads/000203 TMBL-ROV 2000 Säckenrevet Tape 56.mov                   107\n",
      "/uploads/000203 TMBL-ROV 2000 Säcken revet EJ numrerade band.mov         81\n",
      "/uploads/000114 TMBL-ROV 2000 Säckenrevet Tape 55.mov                    67\n",
      "/uploads/010424 Säckenrevet alfa Tape 74.mov                             45\n",
      "/uploads/010424 Säckenrevet beta Tape 74.mov                             38\n",
      "/uploads/990506 TMBL-ROV 1999 Revet Säcken 2 Tape 42.mov                 37\n",
      "/uploads/040522 TMBL-ROV 2004 Säckenrevet.mov                            36\n",
      "/uploads/030317-18 TMBL-ROV 2003 Säckenrevet.mov                         33\n",
      "/uploads/030325 TMBL-ROV 2003 Säckenrevet bioerosion.mov                 32\n",
      "/uploads/000114 TMBL-ROV 2000 Säckenrevet EJ numrerade band.mov          27\n",
      "/uploads/040220 TMBL-ROV 2004 Säckenrevet alfa.mov                       25\n",
      "/uploads/000203 TMBL-ROV 2000 Säcken EJ numrerade band.mov               10\n",
      "/uploads/990506 TMBL-ROV 1999 Revet Säcken Tape 42_SELECTWS.mov           8\n",
      "/uploads/000203 TMBL-ROV 2000 säcken Tape 56.mov                          5\n",
      "/uploads/020130 TMBL-ROV 2002 Säcken transekt 1.mov                       3\n",
      "/uploads/020628 TMBL-ROV 2002 O Hollanderberget Säcken.mov                2\n",
      "/uploads/990813 TMBL-ROV 1999 Storö-Torsö Utsidan rännan tape 48.mov      1\n",
      "Name: fpath, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Movie distribution {species}: \\n\\n{w2_annotations['fpath'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise species distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing locations\n",
    "w2_annotations[\"coord_lon\"] = w2_annotations['coord_lon'].astype(float)\n",
    "w2_annotations[\"coord_lat\"] = w2_annotations['coord_lat'].astype(float)\n",
    "w2_annotations = w2_annotations[(w2_annotations.coord_lon != 0.0) & (w2_annotations.coord_lat != 0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_counts = w2_annotations.groupby([\"coord_lat\", \"coord_lon\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species Distribution for DEEPWATERCORAL in Koster Protected Region\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=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 onload=\"this.contentDocument.open();this.contentDocument.write(atob(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7feca2b8e470>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "import datetime as dt\n",
    "import random as rnd\n",
    "\n",
    "#GBG Coordinates\n",
    "GBG_COORD = [57.7089, 11.9746]\n",
    "\n",
    "coords = [(x,y) for x,y in zip(w2_counts.coord_lat, w2_counts.coord_lon)]\n",
    "\n",
    "# Build map\n",
    "print(f'Species Distribution for {species} in Koster Protected Region')\n",
    "map_gbg = folium.Map(location=GBG_COORD, zoom_start=6, \n",
    "tiles='Stamen Terrain', width=1000, height=500)\n",
    "\n",
    "# Plot coordinates using comprehension list\n",
    "[folium.CircleMarker(coords[i], radius=int(w2_counts['counts'][i]//10),\n",
    "                color='#0080bb', popup=int(w2_counts['counts'][i]), fill_color='#0080bb').add_to(map_gbg) \n",
    "for i in range(len(coords))]\n",
    "\n",
    "# Display map in Jupyter\n",
    "map_gbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
