{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49ece9a",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://panoptes-uploads.zooniverse.org/project_avatar/86c23ca7-bbaa-4e84-8d8a-876819551431.png\" type=\"image/png\" height=100 width=100>\n",
    "</img>\n",
    "\n",
    "\n",
    "<h1 align=\"right\">KSO Tutorials #12: Analyse Zooniverse classifications</h1>\n",
    "<h3 align=\"right\">Written by @jannesgg and @vykanton</h3>\n",
    "<h5 align=\"right\">Last updated: Aug 17th, 2021</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbcdb0",
   "metadata": {},
   "source": [
    "### Step 0: Import Python packages and initiate koster database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65d28bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Zooniverse user········\n",
      "Enter your Zooniverse password········\n",
      "Updated sites\n",
      "Updated movies\n",
      "Updated species\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\koster_data_management\\db_starter\\subjects_uploaded.py:111: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  clip_filenames = meta_df[\"filename\"].str.replace(\".mp4\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated subjects\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import getpass\n",
    "import utils.t12_utils as t12\n",
    "\n",
    "# Add Zooniverse credentials\n",
    "zoo_user = getpass.getpass('Enter your Zooniverse user')\n",
    "zoo_pass = getpass.getpass('Enter your Zooniverse password')\n",
    "\n",
    "# TODO replace the code below to initiate koster db for one line (code below is from \"#3.Build and populate koster database\")\n",
    "import os\n",
    "if os.path.exists(\"koster_lab.db\"):\n",
    "  os.remove(\"koster_lab.db\")\n",
    "else:\n",
    "  print(\"There are no previous database versions\")\n",
    "\n",
    "# Initiate the db\n",
    "%run -i \"../db_starter/init.py\"\n",
    "\n",
    "# Populate the db with info from the csv files\n",
    "%run -i \"../db_starter/static.py\"\n",
    "\n",
    "# Populate the db with info of subjects uploaded to Zooniverse\n",
    "%run -i \"../db_starter/subjects_uploaded.py\" --user $zoo_user --passw $zoo_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf3fb4",
   "metadata": {},
   "source": [
    "### Step 1: Specify the Zooniverse workflow id and version of interest\n",
    "\n",
    "*Note:  A manual export in Zooniverse is required to get the most up-to-date classifications here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed501f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 3, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\koster_data_management\\db_starter\\subjects_uploaded.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Retrieve classifications from the workflow of interest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtotal_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt12\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_classifications\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkflow_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkflow_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubj_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoo_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoo_pass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\koster_data_management\\utils\\t12_utils.py\u001b[0m in \u001b[0;36mget_classifications\u001b[1;34m(workflow_id, workflow_version, subj_type, user, passw)\u001b[0m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     subjects_df = pd.read_csv(\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_export\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 3\n"
     ]
    }
   ],
   "source": [
    "# TODO Display a selectable list of workflow ids with their names and a list of versions of the workflow of interest\n",
    "#workflow_id, workflow_version, subj_type = t13.get_workflows(zoo_user, zoo_pass)\n",
    "    \n",
    "# Temporary example objects\n",
    "workflow_id = 17719\n",
    "workflow_version = 0.0\n",
    "subj_type = \"clip\"\n",
    "\n",
    "# Retrieve classifications from the workflow of interest\n",
    "total_df, class_df = t12.get_classifications(workflow_id, workflow_version, subj_type, zoo_user, zoo_pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8dfb6e",
   "metadata": {},
   "source": [
    "### Step 2: Aggregate classifications received on the workflow of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f4fbde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\koster_data_management\\db_starter\\subjects_uploaded.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmin_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclass_df1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt12\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregrate_classifications\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubj_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magg_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_users\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'class_df' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO Display a selectable list of min number of users, agreement, \n",
    "#agg_user, min_users = t13.set_aggregation_parameters()\n",
    "\n",
    "# Specify the agreement threshold required among cit scientists\n",
    "agg_users = 0.8\n",
    "min_users = 3\n",
    "\n",
    "class_df1 = t12.aggregrate_classifications(class_df, subj_type, agg_users, min_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117cb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d120ad4",
   "metadata": {},
   "source": [
    "### Step 3: Summarise the number of classifications based on the agreement specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb18ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e6a6804",
   "metadata": {},
   "source": [
    "### Step 4: Use the subject explorer widget to get more information about specific subjects and their aggregated classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ab27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all classified subjects from specified workflows\n",
    "total_df, class_df = t13.get_exports(user, password)\n",
    "\n",
    "clips_df = t13.process_clips(total_df, class_df, clips_workflow_id, clips_workflow_version)\n",
    "frames_df = t13.process_frames(db_path, total_df, frames_workflow_id,\n",
    "                               frames_workflow_version, \n",
    "                               \"https://drive.google.com/file/d/1z72CqTtEBtqk6936H1YNrCjc5NRopF0g/view?usp=sharing\")\n",
    "\n",
    "t13.launch_viewer(total_df, clips_df, frames_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ab0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
