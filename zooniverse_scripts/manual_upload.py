#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/clips_manually_uploaded.ipynb
import os, json, csv
import sqlite3
import requests, argparse
from datetime import datetime
from panoptes_client import Project, Panoptes
from db_setup import *
from zooniverse_setup import *


def download_file(url, dstn):
    request = requests.get(url, stream=True)
    with open(dstn, "wb") as dstn_f:
        for chunk in request.iter_content(chunk_size=4096):
            dstn_f.write(chunk)
    return dstn


def download_exports(projt, dstn_sb):

    try:
        meta_subj = projt.describe_export("subjects")
        generated = meta_subj["media"][0]["updated_at"][0:19]
        tdelta = (
            datetime.now() - datetime.strptime(generated, "%Y-%m-%dT%H:%M:%S")
        ).total_seconds()
        age = 300 + int(tdelta / 60)
        print(str(datetime.now())[0:19] + "  Subject export", age, " hours old")
        url_subj = meta_subj["media"][0]["src"]
        file_subj = download_file(url_subj, dstn_sb)
        print(str(datetime.now())[0:19] + "  " + file_subj + " downloaded")
    except:
        print(str(datetime.now())[0:19] + "  Subjects download did not complete")
        return False
    return True


def slice_exports(db_path, dstn_sb, out_location_sb, first_date, last_date):
    k = 0
    m = 0
    with open(out_location_sb, "w", newline="") as file:
        fieldnames = ["subject_id", "subject_set_id", "filename", "created_at"]
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()

        #  open the zooniverse data file using dictreader
        with open(dstn_sb) as f:
            r = csv.DictReader(f)
            for row in r:
                k += 1
                if last_date >= row["created_at"] >= first_date:
                    m += 1
                    # This set up the writer to match the field names above and the variable names of their values:
                    # note we flatten relevant information from the metadata
                    writer.writerow(
                        {
                            "subject_id": row["subject_id"],
                            "subject_set_id": row["subject_set_id"],
                            "filename": json.loads(row["metadata"])["filename"],
                            "created_at": row["created_at"],
                        }
                    )
                    # Connect to koster_db
                    conn = create_connection(db_path)

                    # Add to movies table
                    try:
                        cr = json.loads(row["metadata"])
                        file_name, ext = os.path.splitext(cr["filename"])
                        insert_many(
                            conn,
                            [
                                (
                                    file_name.split("_")[0] + ext,
                                    None,
                                    None,
                                    None,
                                    None,
                                    None,
                                )
                            ],
                            "movies",
                            6,
                        )
                    except:
                        pass
                    # Add to clips table
                    try:
                        cr = json.loads(row["metadata"])
                        lr = json.loads(row["locations"])
                        insert_many(
                            conn,
                            [
                                (
                                    cr["filename"],
                                    lr["0"],
                                    cr["#start_time"] if "#start_time" in cr else None,
                                    cr["#end_time"] if "#end_time" in cr else None,
                                    None,
                                    file_name.split("_")[0] + ext,
                                )
                            ],
                            "clips",
                            6,
                        )
                    except:
                        pass

                    # Add to workflow table
                    try:
                        insert_many(
                            conn, [(row["workflow_id"], "test", 1, 20)], "workflows", 4
                        )
                    except:
                        pass
                    # Add to subjects table
                    try:
                        insert_many(
                            conn,
                            [
                                (
                                    row["subject_id"],
                                    row["workflow_id"],
                                    row["subject_set_id"],
                                    row["classifications_count"],
                                    row["retired_at"],
                                    row["retirement_reason"],
                                    row["created_at"],
                                    cr["filename"],
                                )
                            ],
                            "subjects",
                            8,
                        )
                    except:
                        pass
                    conn.commit()

    print(
        str(datetime.now())[0:19]
        + "  Subjects file:"
        + " "
        + str(k)
        + " lines read and inspected"
        + " "
        + str(m)
        + " records selected and copied"
    )
    return True


def main():
    "Handles argument parsing and launches the correct function."
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--user", "-u", help="Zooniverse username", type=str, required=True
    )
    parser.add_argument(
        "--password", "-p", help="Zooniverse password", type=str, required=True
    )
    parser.add_argument(
        "-db",
        "--db_path",
        type=str,
        help="the absolute path to the database file",
        default=r"koster_lab.db",
        required=True,
    )

    args = parser.parse_args()

    project = auth_session(args.user, args.password)

    # Specify the last and first dates when subjects were manually uploaded
    last_date = "2020-01-10 00:00:00 UTC"
    first_date = "2019-11-17 00:00:00 UTC"

    # Specify the location to write the csv files
    dstn_subj = "../all_subjects.csv"
    out_location_subj = "../manually_uploaded_subjects.csv"

    print(download_exports(project, dstn_subj))
    print(
        slice_exports(args.db_path, dstn_subj, out_location_subj, first_date, last_date)
    )


if __name__ == "__main__":
    main()
