#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/process_clip_classifications.ipynb
# Import required packages
import os, csv, json, sys
import operator, argparse
import requests
import pandas as pd
from datetime import datetime
from db_setup import *
from panoptes_client import Project, Panoptes

# Specify the workflow of interest and its version
workflow_1 = 11767
workflow_1_version = 227


class AuthenticationError(Exception):
    pass


def auth_session(username, password):
    # Connect to Zooniverse with your username and password
    auth = Panoptes.connect(username=username, password=password)

    if not auth.logged_in:
        raise AuthenticationError("Your credentials are invalid. Please try again.")

    # Specify the project number of the koster lab
    project = Project(9747)

    return project


def download_file(url, dstn):
    request = requests.get(url, stream=True)
    with open(dstn, "wb") as dstn_f:
        for chunk in request.iter_content(chunk_size=4096):
            dstn_f.write(chunk)
    return dstn


def download_exports(projt, dstn_cl):
    # replace path and filename strings for where you want the exports saved in the next two lines:
    try:
        meta_class = projt.describe_export("classifications")
        generated = meta_class["media"][0]["updated_at"][0:19]
        tdelta = (
            datetime.now() - datetime.strptime(generated, "%Y-%m-%dT%H:%M:%S")
        ).total_seconds()
        age = 300 + int(tdelta / 60)
        print(str(datetime.now())[0:19] + "  Classifications export", age, " hours old")
        url_class = meta_class["media"][0]["src"]
        file_class = download_file(url_class, dstn_cl)
        print(str(datetime.now())[0:19] + "  " + file_class + " downloaded")
    except:
        print(str(datetime.now())[0:19] + "  Classifications download did not complete")
        return False
    return True


def include_class(class_record):
    #  define a function that returns True or False based on whether the argument record is to be included or not in
    #  the output file based on the conditional clauses.
    #  many other conditions could be set up to determine if a record is to be processed and the flattened data
    #  written to the output file. Any or all of these conditional tests that are not needed can be deleted or
    # commented out with '#' placed in front of the line(s)of code that are not required.

    if int(class_record["workflow_id"]) == workflow_1:
        pass  # replace'!= 0000' with '== xxxx' where xxxx is the workflow to include.  This is also useful to
        # exclude a specific workflow as well.
    else:
        return False
    if float(class_record["workflow_version"]) >= workflow_1_version:
        pass  # replace '001.01' with first version of the workflow to include.
    else:
        return False
    if 100000000 >= int(class_record["subject_ids"]) >= 0000:
        pass  # replace upper and lower subject_ids to include only a specified range of subjects - This is
        # a very useful slice since subjects are selected together and can still be aggregated.
    else:
        return False
    if not class_record["gold_standard"] and not class_record["expert"]:
        pass  # this filters for gold standard classifications only
    else:
        return False
    if (
        "2100-00-10 00:00:00 UTC"
        >= class_record["created_at"]
        >= "2000-00-10 00:00:00 UTC"
    ):
        pass  # replace earliest and latest created_at date and times to select records commenced in a
        #  specific time period
    else:
        return False
    # otherwise :
    return True


def slice_exports(dstn_cl, out_location_cl):
    with open(out_location_cl, "w", newline="") as file:
        fieldnames = [
            "classification_id",
            "user_name",
            "user_id",
            "user_ip",
            "workflow_id",
            "workflow_name",
            "workflow_version",
            "created_at",
            "gold_standard",
            "expert",
            "metadata",
            "annotations",
            "subject_data",
            "subject_ids",
        ]
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()

        # this area for initializing counters, status lists and loading pick lists into memory:
        i = 0
        j = 0

        #  open the zooniverse data file using dictreader
        with open(dstn_cl) as f:
            r = csv.DictReader(f)
            for row in r:
                i += 1
                if include_class(row):
                    j += 1
                    # This set up the writer to match the field names above and the variable names of their values:
                    writer.writerow(
                        {
                            "classification_id": row["classification_id"],
                            "user_name": row["user_name"],
                            "user_id": row["user_id"],
                            "user_ip": row["user_ip"],
                            "workflow_id": row["workflow_id"],
                            "workflow_name": row["workflow_name"],
                            "workflow_version": row["workflow_version"],
                            "created_at": row["created_at"],
                            "gold_standard": row["gold_standard"],
                            "expert": row["expert"],
                            "metadata": row["metadata"],
                            "annotations": row["annotations"],
                            "subject_data": row["subject_data"],
                            "subject_ids": row["subject_ids"],
                        }
                    )

    # This area prints some basic process info and status
    print(
        str(datetime.now())[0:19]
        + "  Classification file:"
        + " "
        + str(i)
        + " lines read and inspected"
        + " "
        + str(j)
        + " records selected and copied"
    )

    k = 0
    m = 0
    return True


def include(class_record):
    #  define a function that returns True or False based on whether the argument record is to be
    #  included or not in the output file based on the conditional clauses.
    #  many other conditions could be set up to determine if a record is to be processed and the
    #  flattened data written to the output file (see flatten_class_frame for more options).

    if int(class_record["workflow_id"]) == workflow_1:
        pass  # this one selects the workflow to include.
    else:
        return False
    if float(class_record["workflow_version"]) >= workflow_1_version:
        pass  # this one selects the first version of the workflow to include. Note the workflows
        #  must be compatible with the structure (task numbers) choices, and questions (they could
        #  differ in confusions, characteristics or other wording differences.)
    else:
        return False
    # otherwise :
    return True


def load_questions(question_file):
    #  This function loads the question.csv and creates a dictionary in memory with the possible responses
    with open(question_file) as qu_file:
        questdict = csv.DictReader(qu_file)
        questions_answers = {}
        translate_table = dict(
            (ord(char), "") for char in u"!\"#%'()*+,-./:;<=>?@[\]^_`{|}~"
        )
        for quest in questdict:
            questions_answers[
                quest["Question"].upper().translate(translate_table).replace(" ", "")
            ] = (quest["Answers"].upper().translate(translate_table).split())
        return questions_answers


def empty(ques, resp):
    blank = []
    for q1 in range(0, len(ques)):
        blank.append([0 for r1 in resp[q1]])
    return blank


def sort_file(input_file, output_file_sorted, field):
    #  This allows a sort of the output file on a specific field.  Note this is a versatile function
    #  that could be added to any of the flatten_class_xxxx.py scripts (note it needs the import os
    #  and import operator lines added at the top of the script.
    with open(input_file, "r") as in_file:
        in_put = csv.reader(in_file, dialect="excel")
        headers = in_put.__next__()
        print(headers)
        sort = sorted(in_put, key=operator.itemgetter(field))

        with open(output_file_sorted, "w", newline="") as out_file:
            write_sorted = csv.writer(out_file, delimiter=",")
            write_sorted.writerow(headers)
            sort_counter = 0
            for line in sort:
                write_sorted.writerow(line)
                sort_counter += 1
    # clean up temporary file
    try:
        os.remove(input_file)
    except:
        print("temp file not found and deleted")
    return sort_counter


def cal_fraction(ques1, resp1, aggr1, tot):
    for q2 in range(0, len(ques1)):
        for r2 in range(0, len(resp1[q2])):
            aggr1[q2][r2] = int(aggr1[q2][r2] / tot[0] * 100 + 0.45)
    return aggr1


def apply_tests(sub, cl_tot, choicevector, col_head):
    # Apply test 1 - were there enough classifications done to give any answer?
    if cl_tot[sub][0] < 4:
        k = generate_row(
            sub,
            cl_tot[sub],
            "insufficient classifications",
            "",
            col_head,
            ["" for rc in range(0, len(col_head))],
        )
        return k

    # Apply test 2 - are there enough votes to count any species?
    sorted_choice = sorted(choicevector, key=operator.itemgetter(1), reverse=True)
    if sorted_choice[0][1] < 20:
        k = generate_row(
            sub,
            cl_tot[sub],
            "indeterminate choice, no consensus",
            "",
            col_head,
            ["" for rc in range(0, len(col_head))],
        )
        return k

    if len(choicevector) > 1:
        # Apply test 3 - are all classifications single choice?
        if cl_tot[sub][0] == cl_tot[sub][1]:
            if sorted_choice[0][1] - sorted_choice[1][1] >= 45:
                k = generate_row(
                    sub,
                    cl_tot[sub],
                    sorted_choice[0][0],
                    sorted_choice[0][1],
                    col_head,
                    generate_outlist(sorted_choice),
                )
                return
            else:
                k = generate_row(
                    sub,
                    cl_tot[sub],
                    "indeterminate choice",
                    "",
                    col_head,
                    ["" for rc in range(0, len(col_head))],
                )
                return k
        # Apply test 4 - multiple choice classified, strong consensus for one choice
        else:
            if sorted_choice[0][1] - sorted_choice[1][1] >= 45:
                k = generate_row(
                    sub,
                    cl_tot[sub],
                    sorted_choice[0][0],
                    sorted_choice[0][1],
                    col_head,
                    generate_outlist(sorted_choice),
                )
                return k
            else:
                # Apply test 4 - multiple choice classified, strong consensus for
                # multiple choice
                if sorted_choice[1][1] >= 65:
                    for item in sorted_choice:
                        if item[1] > 65:
                            k = generate_row(
                                sub,
                                cl_tot[sub],
                                item[0],
                                item[1],
                                col_head,
                                generate_outlist([item], True),
                            )
                    return
                else:
                    k = generate_row(
                        sub,
                        cl_tot[sub],
                        "indeterminate choice possibly multiple",
                        "",
                        col_head,
                        ["" for rc in range(0, len(col_head))],
                    )
                    return
    else:
        k = generate_row(
            sub,
            cl_tot[sub],
            choicevector[0][0],
            choicevector[0][1],
            col_head,
            generate_outlist(choicevector),
        )
        return k


def generate_row(subjt, cltot, choic, choic_v_f, colmns, outlist):
    new_line = {
        "subject_ids": subjt,
        "classifications": cltot[0],
        "choice": choic,
        "choice v_f": choic_v_f,
    }
    for r7 in range(0, len(colmns)):
        new_line[colmns[r7]] = outlist[r7]
    # writer.writerow(new_line)
    return new_line


def total_animals(choicevector):
    tot_animals = 0
    for r8 in range(0, len(choicevector)):
        for r9 in range(0, len(responses[0]) - 2):
            tot_animals += int(choicevector[r8][2][0][r9]) / 100 * int(responses[0][r9])
    return [
        int(round(tot_animals)),
        int(round((abs(tot_animals - int(tot_animals) - 0.5) + 0.5) * 100)),
    ]


def generate_outlist(choicevector, flg=False):
    # deal with the how many question
    # generate the bin_v_f list for the first choice in choicevector
    bin_v_f = []
    tot_v_f = 0
    for r4 in range(0, len(responses[0])):
        if choicevector[0][2][0][r4] > 0:
            bin_v_f.append((int(responses[0][r4]), choicevector[0][2][0][r4]))
            tot_v_f += int(choicevector[0][2][0][r4])
    if (
        len(bin_v_f) > 1
    ):  # multiple bins (ie counting errors or some misidentification occurred)
        binvf = sorted(bin_v_f, key=operator.itemgetter(1))
        if binvf[0][1] >= binvf[1][1] + 45:  # good consensus for lowest bin:
            out_list[0] = binvf[0][0]  # everyone saw at least this many animals
            out_list[1] = tot_v_f
        else:
            binvf = sorted(bin_v_f, key=operator.itemgetter(1), reverse=True)
            if binvf[0][1] >= binvf[1][1] + 45:  # strong consensus for highest bin:
                out_list[0] = binvf[0][0]
                out_list[1] = binvf[0][1]
            else:  # no strong consensus - revert to total animals reported across
                # all classifications for this subject
                if flg:  # multiple choice so total animals have a unknown split
                    out_list[0] = "indeterminate count, multiple choice"
                    out_list[1] = ""
                else:
                    out_list[0] = total_animals(choicevector)[0]
                    out_list[1] = total_animals(choicevector)[1]
    else:
        # only one how_many bin:
        out_list[0] = bin_v_f[0][0]
        out_list[1] = bin_v_f[0][1]

    # deal with the rest of the questions
    c1 = 1
    for q5 in range(1, len(questions)):
        for r5 in range(0, len(responses[q5])):
            c1 += 1
            out_list[c1] = choicevector[0][2][q5][r5]

    # optional removes 0's for blank spaces
    # for r6 in range(0, len(out_list)):
    #     if out_list[r6] == 0:
    #         out_list[r6] = ''
    return out_list


def main():

    "Handles argument parsing and launches the correct function."
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--user", "-u", help="Zooniverse username", type=str, required=True
    )
    parser.add_argument(
        "--password", "-p", help="Zooniverse password", type=str, required=True
    )
    parser.add_argument(
        "-db",
        "--db_path",
        type=str,
        help="the absolute path to the database file",
        default=r"koster_lab.db",
        required=True,
    )
    parser.add_argument(
        "--question_path", "-q", help="Path to questions file", type=str, required=True
    )
    args = parser.parse_args()

    project = auth_session(args.user, args.password)

    # Specify the location to write the csv files
    all_class = "../all_classifications.csv"
    w1_class = "../workflow1_classifications.csv"

    print(download_exports(project, all_class))
    print(slice_exports(all_class, w1_class))

    # The questions and choices files used to set up the survey project:
    question_file = args.question_path

    # Output file names (whatever you want them to be)
    out_w1_class = "../flatten_class_w1.csv"
    agg_w1_class = "../flatten_class_w1_aggregate.csv"

    with open(out_w1_class, "w", newline="") as ou_file:
        fieldnames = [
            "classification_id",
            "subject_ids",
            "created_at",
            "user_name",
            "user_ip",
            "choice",
            "how_many",
            "first_time",
            "subject_choices",
            "all_choices",
        ]
        writer = csv.DictWriter(ou_file, fieldnames=fieldnames)
        writer.writeheader()

        # this area for initializing counters, status lists and loading pick lists into memory:
        rc2 = 0
        rc1 = 0
        wc1 = 0
        #  this loads the question.csv as a dictionary we can split to get the question labels
        #  and possible responses we need to breakout the survey data.  It should produce the same
        #  question and response labels as the project builder but strange characters in the questions
        #  may need to be individually dealt with by adding them to the translation table in the function.
        q_a = load_questions(question_file)
        questions = list(q_a.keys())
        responses = list(q_a.values())

        #  open the zooniverse data file using dictreader, and load the more complex json strings
        #  as python objects using json.loads()
    with open(out_w1_class, "w", newline="") as ou_file:
        fieldnames = [
            "classification_id",
            "subject_ids",
            "created_at",
            "user_name",
            "user_ip",
            "single_ann_clip_choice",
            "single_ann_clip_how_many",
            "single_ann_clip_first_time",
            "single_ann_clip_trash",
        ]
        writer = csv.DictWriter(ou_file, fieldnames=fieldnames)
        writer.writeheader()

        # this area for initializing counters, status lists and loading pick lists into memory:
        rc2 = 0
        rc1 = 0
        wc1 = 0

        #  create a dictionary with the same question and response labels as the project builder.
        questions = ["INDIVIDUAL", "FIRSTTIME", "TYPEOFOBJECT"]
        responses = [
            ["1", "2", "3", "4"],
            ["0S", "1S", "2S", "3S", "4S", "5S", "6S", "7S", "8S", "9S"],
            ["FISHING", "MATERIALLITTER"],
        ]

        #  open the zooniverse data file using dictreader, and load the more complex json strings
        #  as python objects using json.loads()
        with open(w1_class) as class_file:
            classifications = csv.DictReader(class_file)
            for row in classifications:
                rc2 += 1
                # useful for debugging - set the number of record to process at a low number ~1000
                if (
                    rc2 == 150000
                ):  # one more than the last line of zooniverse file to read if not EOF
                    break
                if include(row) is True:
                    rc1 += 1
                    annotations = json.loads(row["annotations"])

                    # reset field variables for the survey task for each new row
                    choice = ""
                    answer = ["" for q4 in questions]

                    for task in annotations:
                        # If the workflow has additional tasks or you want to add other general utilities
                        # blocks, put them here before the survey task, so the writer block will have the
                        # all the data it needs prior to the end of the survey task block.

                        # The survey task block:
                        try:
                            #  main survey task recognized by project specific task number - in this case 'T0'
                            #  you need this to match your own project - it may be different!
                            if task["task"] == "T4":
                                try:
                                    for species in task["value"]:
                                        choice = species["choice"]
                                        answer_vector = empty(questions, responses)

                                        for q in range(0, len(questions)):
                                            try:
                                                answer[q] = [
                                                    val
                                                    for key, val in species[
                                                        "answers"
                                                    ].items()
                                                    if questions[q] in key
                                                ]
                                            except KeyError:
                                                continue

                                        # This sets up the writer to match the field names above and the
                                        # variable names of their values. Note we write one line per
                                        # subject_choices:
                                        wc1 += 1
                                        writer.writerow(
                                            {
                                                "classification_id": row[
                                                    "classification_id"
                                                ],
                                                "subject_ids": row["subject_ids"],
                                                "created_at": row["created_at"],
                                                "user_name": row["user_name"],
                                                "user_ip": row["user_ip"],
                                                "single_ann_clip_choice": choice,
                                                "single_ann_clip_how_many": "".join(
                                                    map(str, answer[0])
                                                ),
                                                "single_ann_clip_first_time": "".join(
                                                    map(str, answer[1])
                                                ).replace("S", ""),
                                                "single_ann_clip_trash": "".join(
                                                    map(str, answer[2])
                                                ),
                                            }
                                        )
                                except KeyError:
                                    continue
                        except KeyError:
                            continue

    # This area prints some basic process info and status
    print(
        rc2,
        "lines read and inspected.",
        rc1,
        "records processed and",
        wc1,
        "lines written.",
    )

    # Aggregate the classifications

    # Load the csv as df to handle with pandas
    w1_data = pd.read_csv(out_w1_class)

    # Calculate the number of different classifications per subject
    w1_data["class_subject"] = w1_data.groupby("subject_ids")[
        "classification_id"
    ].transform("nunique")

    # Select subjects with at least 4 different classifications
    w1_data = w1_data[w1_data.class_subject > 3]

    # Calculate the proportion of users that agreed on their classifications
    w1_data["class_n"] = w1_data.groupby(["subject_ids", "single_ann_clip_choice"])[
        "classification_id"
    ].transform("count")
    w1_data["class_prop"] = w1_data.class_n / w1_data.class_subject

    # Select subjects where at least 80% of the users agree in their classification
    w1_data = w1_data[w1_data.class_prop > 0.8]

    # extract the median of the second where the animal/object is and the number of animals
    w1_data = w1_data.groupby(["subject_ids", "single_ann_clip_choice"], as_index=False)
    w1_data = pd.DataFrame(
        w1_data[["single_ann_clip_how_many", "single_ann_clip_first_time"]].median()
    )

    # save csv file of the classified subjects
    w1_data.to_csv(agg_w1_class, index=False, header=True)

    # Add to agg_classifications db
    conn = create_connection(args.db_path)

    try:
        insert_many(conn, [tuple(i) for i in w1_data.values], "agg_classifications", 4)
    except sqlite3.Error as e:
        print(e)

    conn.commit()

    print("Aggregation complete")


if __name__ == "__main__":
    main()
