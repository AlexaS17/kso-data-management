{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update database with manually uploaded clips\n",
    "Script to populate the koster lab database with information of clips that have been manually uploaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "We first download information from all subjects uploaded to the Koster lab project (#9747) using the [Python SDK for Panoptes!](https://github.com/zooniverse/panoptes-python-client). Then, we select those subjects manually uploaded and update the kosted db with the filename of the original movie, when the clip starts and the subject id.\n",
    "Note, only Zooniverse project collaborators can retrieve subjects information from the Koster lab Zooniverse project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, json, csv\n",
    "import sqlite3\n",
    "import requests, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from panoptes_client import Project, Panoptes\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify project-specific info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Zooniverse with your username and password\n",
    "Panoptes.connect(username='', password='')\n",
    "\n",
    "# Specify the project number of the koster lab\n",
    "project = Project(9747)\n",
    "\n",
    "# Specify the last and first dates when subjects were manually uploaded\n",
    "last_date = '2020-02-03 20:30:00 UTC'\n",
    "#last_date = \"2019-11-18 00:00:00 UTC\"\n",
    "first_date = '2019-11-17 00:00:00 UTC'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download subject information from Zooniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the export subjects\n",
    "export = project.get_export('subjects')\n",
    "\n",
    "# Save the response as pandas data frame\n",
    "rawdata = pd.read_csv(\n",
    "    io.StringIO(export.content.decode(\"utf-8\")),\n",
    "    usecols=[\n",
    "        \"subject_id\",\n",
    "        \"metadata\",\n",
    "        \"created_at\",\n",
    "        \"workflow_id\",\n",
    "        \"subject_set_id\",\n",
    "        \"classifications_count\",\n",
    "        \"retired_at\",\n",
    "        \"retirement_reason\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select manually uploaded clip subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter manually uploaded subjects\n",
    "man_data = rawdata[\n",
    "    (last_date >= rawdata.created_at) & (first_date <= rawdata.created_at)\n",
    "]\n",
    "\n",
    "# filter clip subjects\n",
    "man_data = man_data[man_data[\"metadata\"].str.contains(\".mp4\")].reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten the subjects metadata information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the metadata information\n",
    "flat_metadata = pd.json_normalize(man_data.metadata.apply(json.loads))\n",
    "\n",
    "# Select the filename of the clips\n",
    "clip_filenames = flat_metadata[\"filename\"]\n",
    "\n",
    "# Get the starting time of clips in relation to the original movie\n",
    "# split the filename, select the last section, and remove the extension type\n",
    "flat_metadata[\"start_time\"] = (\n",
    "    clip_filenames.str.rsplit(\"_\", 1).str[-1].str.replace(\".mp4\", \"\")\n",
    ")\n",
    "\n",
    "# Extract the filename of the original movie\n",
    "flat_metadata[\"movie_filename\"] = flat_metadata.apply(\n",
    "    lambda x: x[\"filename\"].replace(\"_\" + x[\"start_time\"], \"\"), axis=1\n",
    ")\n",
    "\n",
    "# Get the end time of clips in relation to the original movie\n",
    "flat_metadata[\"start_time\"] = pd.to_numeric(\n",
    "    flat_metadata[\"start_time\"], downcast=\"signed\"\n",
    ")\n",
    "flat_metadata[\"end_time\"] = flat_metadata[\"start_time\"] + 10\n",
    "\n",
    "# select only relevant columns\n",
    "flat_metadata = flat_metadata[\n",
    "    [\"filename\", \"movie_filename\", \"start_time\", \"end_time\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include movie_ids \n",
    "Retrieve \"id\" and \"filename\" from the \"movies\" table of the koster db to add movie \"flat_metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the id and filename from the movies table\n",
    "#flat_metadata[\"movie_id\"] = flat_metadata.apply(lambda x: get_id(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moviename(row):\n",
    "\n",
    "    # Currently we discard sites that have no lat or lon coordinates, since site descriptions are not unique\n",
    "    # it becomes difficult to match this information otherwise\n",
    "\n",
    "    try:\n",
    "        filename, ext = os.path.splitext(row[\"movie_filename\"])\n",
    "        filename = filename.rsplit(\"_\", 1)[0]\n",
    "    except:\n",
    "        filename = 0\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_metadata[\"movie_filename\"] = flat_metadata.apply(lambda x: get_moviename(x), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile all the information and update the clips and subjects tables of koster db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop metadata column and define clip creation date as time uploaded to Zooniverse\n",
    "man_data = man_data.drop(columns=\"metadata\")\n",
    "\n",
    "# Combine the information\n",
    "comb_data = pd.concat([man_data, flat_metadata], axis=1)\n",
    "\n",
    "# Select information to include in the clips table\n",
    "clips = comb_data.drop(\n",
    "    columns=[\n",
    "        \"subject_id\",\n",
    "        #\"movie_filename\",\n",
    "        \"workflow_id\",\n",
    "        \"subject_set_id\",\n",
    "        \"classifications_count\",\n",
    "        \"retired_at\",\n",
    "        \"retirement_reason\",\n",
    "    ]\n",
    ").rename(columns={\"created_at\": \"clipped_date\", \"index\": \"id\"})\n",
    "\n",
    "\n",
    "# Combine the info to include in the subjects table\n",
    "subjects = comb_data.rename(\n",
    "    columns={\n",
    "        \"created_at\": \"zoo_upload_date\",\n",
    "        \"index\": \"clip_id\",\n",
    "        \"retirement_reason\": \"retirement_criteria\",\n",
    "        \"subject_id\": \"id\",\n",
    "    }\n",
    ")\n",
    "\n",
    "subjects = subjects[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"workflow_id\",\n",
    "        \"subject_set_id\",\n",
    "        \"classifications_count\",\n",
    "        \"retired_at\",\n",
    "        \"retirement_criteria\",\n",
    "        \"zoo_upload_date\",\n",
    "        \"clip_id\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "#update the tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_csv_from_google_drive(id):\n",
    "\n",
    "    # Download the csv files stored in Google Drive with initial information about\n",
    "    # the movies and the species\n",
    "\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params={\"id\": id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = {\"id\": id, \"confirm\": token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith(\"download_warning\"):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "# Download the csv with movies information from the google drive\n",
    "movies_csv_resp = download_csv_from_google_drive('1LL-Ah_FIkBiGKEldYvuhNeL2NyOvKBip')\n",
    "movies_df = pd.read_csv(io.StringIO(movies_csv_resp.content.decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_merged = clips.merge(movies_df,left_on='movie_filename',\n",
    "                           right_on='FilenameCurrent',how='outer')\n",
    "\n",
    "clips_merged.movie_filename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips.movie_filename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
