{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Zooniverse classifications of clips\n",
    "Script to retrieve clip classification data from Zooniverse and update the Koster lab database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download classifications from Zooniverse\n",
    "Download the most up-to-date classifications provided by Zooniverse users to the Koster lab project (#9747) using the [Python SDK for Panoptes!](https://github.com/zooniverse/panoptes-python-client).\n",
    "Note, only Zooniverse project collaborators can retrieve classifications from the Koster lab Zooniverse project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import operator\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from panoptes_client import Project, Panoptes\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify project-specific info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Zooniverse with your username and password\n",
    "Panoptes.connect(username='', password='')\n",
    "\n",
    "# Specify the project number of the koster lab\n",
    "project = Project(9747)\n",
    "\n",
    "# Specify the workflow of interest and its version\n",
    "workflow_1 = 11767\n",
    "workflow_1_version = 227\n",
    "\n",
    "# Specify the location to write the csv files                \n",
    "all_class = '../all_classifications.csv'\n",
    "w1_class = '../workflow1_classifications.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the functions to download the classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, dstn):\n",
    "    request = requests.get(url, stream=True)\n",
    "    with open(dstn, 'wb') as dstn_f:\n",
    "        for chunk in request.iter_content(chunk_size=4096):\n",
    "            dstn_f.write(chunk)\n",
    "    return dstn\n",
    "\n",
    "\n",
    "def download_exports(projt, dstn_cl):\n",
    "    # replace path and filename strings for where you want the exports saved in the next two lines:\n",
    "    try:\n",
    "        meta_class = projt.describe_export('classifications')\n",
    "        generated = meta_class['media'][0]['updated_at'][0:19]\n",
    "        tdelta = (datetime.now() - datetime.strptime(generated, '%Y-%m-%dT%H:%M:%S')).total_seconds()\n",
    "        age = (300 + int(tdelta / 60))\n",
    "        print(str(datetime.now())[0:19] + '  Classifications export', age, ' hours old')\n",
    "        url_class = meta_class['media'][0]['src']\n",
    "        file_class = download_file(url_class, dstn_cl)\n",
    "        print(str(datetime.now())[0:19] + '  ' + file_class + ' downloaded')\n",
    "    except:\n",
    "        print(str(datetime.now())[0:19] + '  Classifications download did not complete')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def include_class(class_record):\n",
    "    #  define a function that returns True or False based on whether the argument record is to be included or not in\n",
    "    #  the output file based on the conditional clauses.\n",
    "    #  many other conditions could be set up to determine if a record is to be processed and the flattened data\n",
    "    #  written to the output file. Any or all of these conditional tests that are not needed can be deleted or\n",
    "    # commented out with '#' placed in front of the line(s)of code that are not required.\n",
    "\n",
    "    if int(class_record['workflow_id']) == workflow_1:\n",
    "        pass  # replace'!= 0000' with '== xxxx' where xxxx is the workflow to include.  This is also useful to\n",
    "        # exclude a specific workflow as well.\n",
    "    else:\n",
    "        return False\n",
    "    if float(class_record['workflow_version']) >= workflow_1_version:\n",
    "        pass  # replace '001.01' with first version of the workflow to include.\n",
    "    else:\n",
    "        return False\n",
    "    if 100000000 >= int(class_record['subject_ids']) >= 0000:\n",
    "        pass  # replace upper and lower subject_ids to include only a specified range of subjects - This is\n",
    "        # a very useful slice since subjects are selected together and can still be aggregated.\n",
    "    else:\n",
    "        return False\n",
    "    if not class_record['gold_standard'] and not class_record['expert']:\n",
    "        pass  # this filters for gold standard classifications only\n",
    "    else:\n",
    "        return False\n",
    "    if '2100-00-10 00:00:00 UTC' >= class_record['created_at'] >= '2000-00-10 00:00:00 UTC':\n",
    "        pass  # replace earliest and latest created_at date and times to select records commenced in a\n",
    "        #  specific time period\n",
    "    else:\n",
    "        return False\n",
    "    # otherwise :\n",
    "    return True\n",
    "\n",
    "\n",
    "def slice_exports(dstn_cl, out_location_cl):\n",
    "    with open(out_location_cl, 'w', newline='') as file:\n",
    "        fieldnames = ['classification_id',\n",
    "                      'user_name', 'user_id',\n",
    "                      'user_ip', 'workflow_id',\n",
    "                      'workflow_name',\n",
    "                      'workflow_version',\n",
    "                      'created_at',\n",
    "                      'gold_standard',\n",
    "                      'expert',\n",
    "                      'metadata',\n",
    "                      'annotations',\n",
    "                      'subject_data',\n",
    "                      'subject_ids']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # this area for initializing counters, status lists and loading pick lists into memory:\n",
    "        i = 0\n",
    "        j = 0\n",
    "\n",
    "        #  open the zooniverse data file using dictreader\n",
    "        with open(dstn_cl) as f:\n",
    "            r = csv.DictReader(f)\n",
    "            for row in r:\n",
    "                i += 1\n",
    "                if include_class(row):\n",
    "                    j += 1\n",
    "                    # This set up the writer to match the field names above and the variable names of their values:\n",
    "                    writer.writerow({'classification_id': row['classification_id'],\n",
    "                                     'user_name': row['user_name'],\n",
    "                                     'user_id': row['user_id'],\n",
    "                                     'user_ip': row['user_ip'],\n",
    "                                     'workflow_id': row['workflow_id'],\n",
    "                                     'workflow_name': row['workflow_name'],\n",
    "                                     'workflow_version': row['workflow_version'],\n",
    "                                     'created_at': row['created_at'],\n",
    "                                     'gold_standard': row['gold_standard'],\n",
    "                                     'expert': row['expert'],\n",
    "                                     'metadata': row['metadata'],\n",
    "                                     'annotations': row['annotations'],\n",
    "                                     'subject_data': row['subject_data'],\n",
    "                                     'subject_ids': row['subject_ids']})\n",
    "\n",
    "    # This area prints some basic process info and status\n",
    "    print(str(datetime.now())[0:19] + '  Classification file:' +\n",
    "          ' ' + str(i) + ' lines read and inspected' + ' ' + str(j) + ' records selected and copied')\n",
    "\n",
    "    k = 0\n",
    "    m = 0\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the classifications from Zooniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(download_exports(project, all_class))\n",
    "    print(slice_exports(all_class, w1_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregrate Zooniverse classifications\n",
    "Combine the classifications of multiple users and aggregrate them to have one classification per clip. For example, clip_001 contains \"lobster\" and \"sponge\" at second 1 and 6, respectively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify project-specific info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The questions and choices files used to set up the survey project:\n",
    "question_file = '../questions_9Mar2020.csv'\n",
    "\n",
    "# Output file names (whatever you want them to be)\n",
    "out_w1_class = '../flatten_class_w1.csv'  # a sort deletes this file after use\n",
    "sorted_w1_class = '../flatten_class_w1_sorted.csv'\n",
    "aggregate_w1_class = '../flatten_class_w1_aggregate.csv'\n",
    "columns_w1_class = '../flatten_class_w1_filtered.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the functions to aggregate the classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def include(class_record):\n",
    "    #  define a function that returns True or False based on whether the argument record is to be\n",
    "    #  included or not in the output file based on the conditional clauses.\n",
    "    #  many other conditions could be set up to determine if a record is to be processed and the\n",
    "    #  flattened data written to the output file (see flatten_class_frame for more options).\n",
    "\n",
    "    if int(class_record['workflow_id']) == workflow_1 :\n",
    "        pass  # this one selects the workflow to include.\n",
    "    else:\n",
    "        return False\n",
    "    if float(class_record['workflow_version']) >= workflow_1_version:\n",
    "        pass  # this one selects the first version of the workflow to include. Note the workflows\n",
    "        #  must be compatible with the structure (task numbers) choices, and questions (they could\n",
    "        #  differ in confusions, characteristics or other wording differences.)\n",
    "    else:\n",
    "        return False\n",
    "    # otherwise :\n",
    "    return True\n",
    "\n",
    "\n",
    "def load_questions():\n",
    "    #  This function loads the question.csv and creates a dictionary in memory with the possible responses\n",
    "    with open(question_file) as qu_file:\n",
    "        questdict = csv.DictReader(qu_file)\n",
    "        questions_answers = {}\n",
    "        translate_table = dict((ord(char), '') for char in u'!\"#%\\'()*+,-./:;<=>?@[\\]^_`{|}~')\n",
    "        for quest in questdict:\n",
    "            questions_answers[quest['Question'].upper().translate(translate_table).replace(' ', '')] \\\n",
    "                = quest['Answers'].upper().translate(translate_table).split()\n",
    "        return questions_answers\n",
    "\n",
    "\n",
    "def empty(ques, resp):\n",
    "    blank = []\n",
    "    for q1 in range(0, len(ques)):\n",
    "        blank.append([0 for r1 in resp[q1]])\n",
    "    return blank\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up output file structure with desired fields\n",
    "The list of field names must include each field required in the output. The names, and order must be exactly the same here as in the writer statement near the end of the program. The names and order are arbitrary - your choice, as long as they are the same in both locations.\n",
    "Additional fields from the classification file can be added or removed as required.  The other flatten_class blocks could be added to this demo similarly as they are added to flatten-class_frame either the general utility blocks or any other blocks if the workflow has more that the one survey task in it. These blocks should be added before the first survey task immediately after \"for task in annotations'. As code blocks are added to flatten the annotations JSON, columns need to be added to contain each newly split out group of data. Add each one using the format \"' new_field_name',\" .  Similarly fields can be removed from both places to reduce the file size if the information is not needed for the current purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_w1_class, 'w', newline='') as ou_file:\n",
    "    fieldnames = ['classification_id',\n",
    "                  'subject_ids',\n",
    "                  'created_at',\n",
    "                  'user_name',\n",
    "                  'user_ip',\n",
    "                  'choice',\n",
    "                  'how_many',\n",
    "                  'first_time\",\n",
    "                  'subject_choices',\n",
    "                  'all_choices'\n",
    "                  ]\n",
    "    writer = csv.DictWriter(ou_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # this area for initializing counters, status lists and loading pick lists into memory:\n",
    "    rc2 = 0\n",
    "    rc1 = 0\n",
    "    wc1 = 0\n",
    "    #  this loads the question.csv as a dictionary we can split to get the question labels\n",
    "    #  and possible responses we need to breakout the survey data.  It should produce the same\n",
    "    #  question and response labels as the project builder but strange characters in the questions\n",
    "    #  may need to be individually dealt with by adding them to the translation table in the function.\n",
    "    q_a = load_questions()\n",
    "    questions = list(q_a.keys())\n",
    "    responses = list(q_a.values())\n",
    "\n",
    "    \n",
    "    \n",
    "    #  open the zooniverse data file using dictreader, and load the more complex json strings\n",
    "    #  as python objects using json.loads()\n",
    "    with open(w1_class) as class_file:\n",
    "        classifications = csv.DictReader(class_file)\n",
    "        for row in classifications:\n",
    "            rc2 += 1\n",
    "            # useful for debugging - set the number of record to process at a low number ~1000\n",
    "            if rc2 == 150000:  # one more than the last line of zooniverse file to read if not EOF\n",
    "                break\n",
    "            if include(row) is True:\n",
    "                rc1 += 1\n",
    "                annotations = json.loads(row['annotations'])\n",
    "\n",
    "                # reset field variables for the survey task for each new row\n",
    "                choice = ''\n",
    "                answer = ['' for q4 in questions]\n",
    "\n",
    "                for task in annotations:\n",
    "                    # If the workflow has additional tasks or you want to add other general utilities\n",
    "                    # blocks, put them here before the survey task, so the writer block will have the\n",
    "                    # all the data it needs prior to the end of the survey task block.\n",
    "\n",
    "                    # The survey task block:\n",
    "                    try:\n",
    "                        #  main survey task recognized by project specific task number - in this case 'T0'\n",
    "                        #  you need this to match your own project - it may be different!\n",
    "                        if task['task'] == 'T4':\n",
    "                            try:\n",
    "                                m_s = 1\n",
    "                                b = 1\n",
    "                                for species in task['value']:\n",
    "                                    m_s = m_s * b  # set up test for multiple species in one classification\n",
    "                                    b = b * 0\n",
    "                                    choice = species['choice']\n",
    "                                    answer_vector = empty(questions, responses)\n",
    "\n",
    "                                    for q in range(0, len(questions)):\n",
    "                                        try:\n",
    "                                            answer[q] = species['answers'][questions[q]]\n",
    "                                            # prepare answer_vectors that will make aggregation easier\n",
    "                                            # This section is optional but produces a data structure that\n",
    "                                            # will be needed for a future aggregate_survey script.\n",
    "                                            for r in range(0, len(responses[q])):\n",
    "                                                if responses[q][r] == answer[q]:\n",
    "                                                    answer_vector[q][r] = 1\n",
    "                                        except KeyError:\n",
    "                                            continue\n",
    "                                    # This sets up the writer to match the field names above and the\n",
    "                                    # variable names of their values. Note we write one line per\n",
    "                                    # subject_choices:\n",
    "                                    wc1 += 1\n",
    "                                    writer.writerow({'classification_id': row['classification_id'],\n",
    "                                                     'subject_ids': row['subject_ids'],\n",
    "                                                     'created_at': row['created_at'],\n",
    "                                                     'user_name': row['user_name'],\n",
    "                                                     'user_ip': row['user_ip'],\n",
    "                                                     'choice': choice,\n",
    "                                                     'how_many': answer[0],\n",
    "                                                     'first_time': answer[1],\n",
    "                                                     'subject_choices': row['subject_ids'] + choice,\n",
    "                                                     'all_choices': json.dumps([m_s, answer_vector])\n",
    "                                                     })\n",
    "                            except KeyError:\n",
    "                                continue\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "\n",
    "# This area prints some basic process info and status\n",
    "print(rc2, 'lines read and inspected', rc1, 'records processed and', wc1, 'lines written')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the classifications\n",
    "defines and run a sort function. Note the last parameter is the field to sort by where fields are numbered starting from '0'  This prepares the file to be aggregated and is necessary for the old fashion aggregation routine I use. (note with pandas the aggregation would take about four lines and the file would not have to be sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_file(input_file, output_file_sorted, field):\n",
    "    #  This allows a sort of the output file on a specific field.  Note this is a versatile function\n",
    "    #  that could be added to any of the flatten_class_xxxx.py scripts (note it needs the import os\n",
    "    #  and import operator lines added at the top of the script.\n",
    "    with open(input_file, 'r') as in_file:\n",
    "        in_put = csv.reader(in_file, dialect='excel')\n",
    "        headers = in_put.__next__()\n",
    "        sort = sorted(in_put, key=operator.itemgetter(field))\n",
    "\n",
    "        with open(output_file_sorted, 'w', newline='') as out_file:\n",
    "            write_sorted = csv.writer(out_file, delimiter=',')\n",
    "            write_sorted.writerow(headers)\n",
    "            sort_counter = 0\n",
    "            for line in sort:\n",
    "                write_sorted.writerow(line)\n",
    "                sort_counter += 1\n",
    "    # clean up temporary file\n",
    "    try:\n",
    "        os.remove(input_file)\n",
    "    except:\n",
    "        print('temp file not found and deleted')\n",
    "    return sort_counter\n",
    "\n",
    "\n",
    "print(sort_file(out_w1_class, sorted_w1_class, 11), 'lines sorted and written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregrate the classifications\n",
    "This next section aggregates the responses for each subject-species and out puts the result with one line per subject-species. Vote fractions are calculated for each question-response and are displayed in a answer_vector format suitable for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_fraction(ques1, resp1, aggr1, tot):\n",
    "    for q2 in range(0, len(ques1)):\n",
    "        for r2 in range(0, len(resp1[q2])):\n",
    "            aggr1[q2][r2] = int(aggr1[q2][r2] / tot[0] * 100 + .45)\n",
    "    return aggr1\n",
    "\n",
    "\n",
    "with open(aggregate_w1_class, 'w', newline='') as ag_file:\n",
    "    fieldnames = ['subject_ids', 'classifications', 'choice', 'aggregated_vector']\n",
    "    writer = csv.DictWriter(ag_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    #  build a look-up table of classification totals by subject - this is needed for the calculation of\n",
    "    #  vote_fraction.\n",
    "    with open(sorted_w1_class) as so_file:\n",
    "        sorted_file = csv.DictReader(so_file)\n",
    "        subject = ''\n",
    "        class_totals = {}\n",
    "        class_tot = 0\n",
    "        rc3 = 0\n",
    "        for row1 in sorted_file:\n",
    "            rc3 += 1\n",
    "            new_subject = row1['subject_ids']\n",
    "            if new_subject != subject:\n",
    "                if rc3 != 1:\n",
    "                    class_totals[subject] = [class_tot, rc3]\n",
    "                rc3 = 0\n",
    "                subject = new_subject\n",
    "                class_tot = json.loads(row1['all_choices'])[0]\n",
    "            else:\n",
    "                subject = new_subject\n",
    "                class_tot += json.loads(row1['all_choices'])[0]\n",
    "        class_totals[subject] = [class_tot, rc3]\n",
    "\n",
    "    # The old fashion aggregation routine with the vote fraction and file write built in\n",
    "    with open(sorted_w1_class) as so_file:\n",
    "        sorted_file = csv.DictReader(so_file)\n",
    "        subject = ''\n",
    "        subject_choices = ''\n",
    "        rc4 = 0\n",
    "        rc5 = 0\n",
    "        aggregate = empty(questions, responses)\n",
    "        class_count = 1\n",
    "        choice_now = ''\n",
    "        for row2 in sorted_file:\n",
    "            rc4 += 1\n",
    "            new_subject = row2['subject_ids']\n",
    "            new_subject_choices = row2['subject_choices']\n",
    "            all_choices = json.loads(row2['all_choices'])\n",
    "            if new_subject_choices != subject_choices:\n",
    "                if rc4 != 1:  # don't want to output the empty initial values\n",
    "                    rc5 += 1\n",
    "                    aggregate = cal_fraction(questions, responses, aggregate, class_totals[subject])\n",
    "                    new_row = {'subject_ids': subject,\n",
    "                               'classifications': class_totals[subject][0],\n",
    "                               'choice': choice_now,\n",
    "                               'aggregated_vector': json.dumps(aggregate)}\n",
    "                    writer.writerow(new_row)\n",
    "                subject = new_subject\n",
    "                subject_choices = new_subject_choices\n",
    "                choice_now = row2['choice']\n",
    "                all_choices = json.loads(row2['all_choices'])\n",
    "                class_count = all_choices[0]\n",
    "                for q3 in range(0, len(questions)):\n",
    "                    for r3 in range(0, len(responses[q3])):\n",
    "                        aggregate[q3][r3] = all_choices[1][q3][r3]\n",
    "            else:\n",
    "                for que in range(0, len(questions)):\n",
    "                    for res in range(0, len(responses[que])):\n",
    "                        aggregate[que][res] += all_choices[1][que][res]\n",
    "                class_count += all_choices[0]\n",
    "                subject = new_subject\n",
    "                subject_choices = new_subject_choices\n",
    "\n",
    "        # catch the last aggregate after the end of the file is reached\n",
    "        rc5 += 1\n",
    "        aggregate = cal_fraction(questions, responses, aggregate, class_totals[subject])\n",
    "        new_row = {'subject_ids': subject,\n",
    "                   'classifications': class_totals[subject][0],\n",
    "                   'choice': choice_now,\n",
    "                   'aggregated_vector': json.dumps(aggregate)}\n",
    "        writer.writerow(new_row)\n",
    "    print(rc4, 'lines aggregated into', rc5, 'subject-choice categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter classifications based on consensus\n",
    "Apply a filter to accept a consensus by plurality or to determine if the\n",
    "  result is too ambiguous to accept.  Multiple species, if they survive the filter, are output\n",
    "  on separate lines.\n",
    "\n",
    " The details of the filter are as follows:\n",
    "\n",
    "1)  The minimum number of classifications required retain a subject as classified : 4\n",
    "            \n",
    "2)  Then calculate the total v_f for a choice as the sum of the vote fractions for any number\n",
    "            of that species eg 20% say there are one and 30% say there are two present\n",
    "            then 50% agree that species is present\n",
    "    The minimum total v_f to count any species as present : 20%\n",
    "            if no species has a v-f over 20% then mark as 'species indeterminate'.\n",
    "    Apply these limits then, of those that remain:\n",
    "3)          If only one species is identified in any single classification for a subject,\n",
    "                    and the highest total v_f exceeds the next highest total v_f by at least 45%\n",
    "                            report that species as having consensus - see point 5 for calculating\n",
    "                            \"how many\" to report.\n",
    "                    otherwise report subject as 'species indeterminate'        \n",
    "4)          If two or more species are identified in at least one classification for a subject,            \n",
    "                    and if one species's total v_f exceeds the other by at least 45%, report\n",
    "                            only that species see point 5 for calculating \"how many\" to report.\n",
    "                    otherwise                             \n",
    "                            if total v_f for each species exceeds 65% report all such species \n",
    "                            against that subject.\n",
    "                    else report as 'species indeterminate, possibly multiple'\n",
    "                            \n",
    "            \n",
    "5)  If only a single how_many bin exists for the majority species report that how_many and the  \n",
    "    vote fraction for that species as the how many v_f as well.\n",
    "      \n",
    "    If a multiple \"how many\" bins exist for the majority species (count or identification errors): \n",
    "        If the lower count has a good consensus with a v_f higher than the next highest by at \n",
    "        least 45%, use the lower count and the total v_f (ie everyone saw at least that count).\n",
    "        If the higher count has the larger v_f by at least 45% use the higher count and report \n",
    "        only the higher count v_f against it. \n",
    "        Oherwise the count is indeterminate by v_f - calculate the total number of animals \n",
    "        reported for all classifications done for that subject including species eliminated for\n",
    "        low v_f - assume all animals reported are of the majority species type. Report the \n",
    "        fraction of all classifications that reported that number of animals for the subject\n",
    "        as the v_f for this how_many.  Note this can produce errors if there is strong consensus \n",
    "        for multiple species, AND at least one of those has multiple how_many bins with no consensus\n",
    "        on how many of that species exist. In this case the how_many is reported as \"indeterminate \n",
    "        how_many\" \n",
    "            \n",
    "6)  No other filters are applied to the other questions with a simple v_f recorded.\n",
    "\n",
    "This section out_puts the data in a columnar format vs the answer_vector approach above.  In this\n",
    "case the column headings, to make the most sense for the project owner, needs to be manually chosen\n",
    "and entered as list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_headers = ['how_many', 'how_many_vf', 'Resting', 'Standing', 'Moving', 'Eating',\n",
    "                  'Interacting', 'Young', 'No_Young', 'Horns', 'No_Horns', \"Don't_care_yes\", \"Don't_care_no\"]\n",
    "\n",
    "\n",
    "def apply_tests(sub, cl_tot, choicevector, col_head):\n",
    "    # Apply test 1 - were there enough classifications done to give any answer?\n",
    "    if cl_tot[sub][0] < 4:\n",
    "        generate_row(sub, cl_tot[sub], 'insufficient classifications', '',\n",
    "                     col_head, ['' for rc in range(0, len(col_head))])\n",
    "        return\n",
    "\n",
    "    # Apply test 2 - are there enough votes to count any species?\n",
    "    sorted_choice = sorted(choicevector, key=operator.itemgetter(1), reverse=True)\n",
    "    if sorted_choice[0][1] < 20:\n",
    "        generate_row(sub, cl_tot[sub], 'indeterminate choice, no consensus', '',\n",
    "                     col_head, ['' for rc in range(0, len(col_head))])\n",
    "        return\n",
    "\n",
    "    if len(choicevector) > 1:\n",
    "        # Apply test 3 - are all classifications single choice?\n",
    "        if cl_tot[sub][0] == cl_tot[sub][1]:\n",
    "            if sorted_choice[0][1] - sorted_choice[1][1] >= 45:\n",
    "                generate_row(sub, cl_tot[sub], sorted_choice[0][0], sorted_choice[0][1],\n",
    "                             col_head, generate_outlist(sorted_choice))\n",
    "                return\n",
    "            else:\n",
    "                generate_row(sub, cl_tot[sub], 'indeterminate choice', '',\n",
    "                             col_head, ['' for rc in range(0, len(col_head))])\n",
    "                return\n",
    "        # Apply test 4 - multiple choice classified, strong consensus for one choice\n",
    "        else:\n",
    "            if sorted_choice[0][1] - sorted_choice[1][1] >= 45:\n",
    "                generate_row(sub, cl_tot[sub], sorted_choice[0][0], sorted_choice[0][1],\n",
    "                             col_head, generate_outlist(sorted_choice))\n",
    "                return\n",
    "            else:\n",
    "                # Apply test 4 - multiple choice classified, strong consensus for\n",
    "                # multiple choice\n",
    "                if sorted_choice[1][1] >= 65:\n",
    "                    for item in sorted_choice:\n",
    "                        if item[1] > 65:\n",
    "                            generate_row(sub, cl_tot[sub], item[0], item[1],\n",
    "                                         col_head, generate_outlist([item], True))\n",
    "                    return\n",
    "                else:\n",
    "                    generate_row(sub, cl_tot[sub], 'indeterminate choice possibly multiple', '',\n",
    "                                 col_head, ['' for rc in range(0, len(col_head))])\n",
    "                    return\n",
    "    else:\n",
    "        generate_row(sub, cl_tot[sub], choicevector[0][0], choicevector[0][1],\n",
    "                     col_head, generate_outlist(choicevector))\n",
    "        return\n",
    "\n",
    "\n",
    "def generate_row(subjt, cltot, choic, choic_v_f, colmns, outlist):\n",
    "    new_line = {'subject_ids': subjt,\n",
    "                'classifications': cltot[0],\n",
    "                'choice': choic,\n",
    "                'choice v_f': choic_v_f}\n",
    "    for r7 in range(0, len(colmns)):\n",
    "        new_line[colmns[r7]] = outlist[r7]\n",
    "    writer.writerow(new_line)\n",
    "    return None\n",
    "\n",
    "\n",
    "def total_animals(choicevector):\n",
    "    tot_animals = 0\n",
    "    for r8 in range(0, len(choicevector)):\n",
    "        for r9 in range(0, len(responses[0]) - 2):\n",
    "            tot_animals += int(choicevector[r8][2][0][r9]) / 100 * int(responses[0][r9])\n",
    "    return [int(round(tot_animals)), int(round((abs(tot_animals - int(tot_animals) - .5) + .5) * 100))]\n",
    "\n",
    "\n",
    "def generate_outlist(choicevector, flg=False):\n",
    "    # deal with the how many question\n",
    "    # generate the bin_v_f list for the first choice in choicevector\n",
    "    bin_v_f = []\n",
    "    tot_v_f = 0\n",
    "    for r4 in range(0, len(responses[0])):\n",
    "        if choicevector[0][2][0][r4] > 0:\n",
    "            bin_v_f.append((int(responses[0][r4]), choicevector[0][2][0][r4]))\n",
    "            tot_v_f += int(choicevector[0][2][0][r4])\n",
    "    if len(bin_v_f) > 1:  # multiple bins (ie counting errors or some misidentification occurred)\n",
    "        binvf = sorted(bin_v_f, key=operator.itemgetter(1))\n",
    "        if binvf[0][1] >= binvf[1][1] + 45:  # good consensus for lowest bin:\n",
    "            out_list[0] = binvf[0][0]  # everyone saw at least this many animals\n",
    "            out_list[1] = tot_v_f\n",
    "        else:\n",
    "            binvf = sorted(bin_v_f, key=operator.itemgetter(1), reverse=True)\n",
    "            if binvf[0][1] >= binvf[1][1] + 45:  # strong consensus for highest bin:\n",
    "                out_list[0] = binvf[0][0]\n",
    "                out_list[1] = binvf[0][1]\n",
    "            else:  # no strong consensus - revert to total animals reported across\n",
    "                # all classifications for this subject\n",
    "                if flg:  # multiple choice so total animals have a unknown split\n",
    "                    out_list[0] = 'indeterminate count, multiple choice'\n",
    "                    out_list[1] = ''\n",
    "                else:\n",
    "                    out_list[0] = total_animals(choicevector)[0]\n",
    "                    out_list[1] = total_animals(choicevector)[1]\n",
    "    else:\n",
    "        # only one how_many bin:\n",
    "        out_list[0] = bin_v_f[0][0]\n",
    "        out_list[1] = bin_v_f[0][1]\n",
    "\n",
    "    # deal with the rest of the questions\n",
    "    c1 = 1\n",
    "    for q5 in range(1, len(questions)):\n",
    "        for r5 in range(0, len(responses[q5])):\n",
    "            c1 += 1\n",
    "            out_list[c1] = choicevector[0][2][q5][r5]\n",
    "\n",
    "    # optional removes 0's for blank spaces\n",
    "    # for r6 in range(0, len(out_list)):\n",
    "    #     if out_list[r6] == 0:\n",
    "    #         out_list[r6] = ''\n",
    "    return out_list\n",
    "\n",
    "\n",
    "with open(columns_w1_class, 'w', newline='') as co_file:\n",
    "    columns = ['subject_ids', 'classifications', 'choice', 'choice v_f']\n",
    "    columns.extend(column_headers)\n",
    "    fieldnames = columns\n",
    "    writer = csv.DictWriter(co_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    with open(aggregate_w1_class) as agg_file:\n",
    "        aggregated_file = csv.DictReader(agg_file)\n",
    "        out_list = ['' for rc in range(0, len(column_headers))]\n",
    "        subject = ''\n",
    "        choice_vector = []\n",
    "        class_count = 0\n",
    "        rc6 = 0\n",
    "        # collect all the subject data together - again an old fashioned aggregation routine\n",
    "        # with the filter applied to the pooled subject data.\n",
    "        for row3 in aggregated_file:\n",
    "            rc6 += 1\n",
    "            vector = json.loads(row3['aggregated_vector'])\n",
    "            new_subject = row3['subject_ids']\n",
    "            if new_subject != subject:\n",
    "                if rc6 != 1:  # don't want to look at the empty initial values\n",
    "                    apply_tests(subject, class_totals, choice_vector,\n",
    "                                column_headers)\n",
    "                subject = new_subject\n",
    "                total_v_f = 0\n",
    "                for r10 in range(0, len(responses[0])):\n",
    "                    total_v_f += vector[0][r10]\n",
    "                choice_vector = [(row3['choice'], total_v_f, vector)]\n",
    "            else:\n",
    "                total_v_f = 0\n",
    "                for r10 in range(0, len(responses[0])):\n",
    "                    total_v_f += vector[0][r10]\n",
    "                choice_vector.append((row3['choice'], total_v_f, vector))\n",
    "                subject = new_subject\n",
    "\n",
    "        # catch the last aggregate after the end of the file is reached\n",
    "        apply_tests(subject, class_totals, choice_vector, column_headers)\n",
    "print(rc6, 'subject-choices filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the koster lab database with aggregated classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
